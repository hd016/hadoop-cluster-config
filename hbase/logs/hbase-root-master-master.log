Sa 4. Mai 17:22:23 CEST 2019 Starting master on master
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 14923
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 14923
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2019-05-04 17:22:24,539 INFO  [main] util.VersionInfo: HBase 1.2.2
2019-05-04 17:22:24,540 INFO  [main] util.VersionInfo: Source code repository git://asf-dev/home/busbey/projects/hbase revision=3f671c1ead70d249ea4598f1bbcc5151322b3a13
2019-05-04 17:22:24,540 INFO  [main] util.VersionInfo: Compiled by busbey on Fri Jul  1 08:28:55 CDT 2016
2019-05-04 17:22:24,540 INFO  [main] util.VersionInfo: From source with checksum 7ac43c3d2f62f134b2a6aa1a05ad66ac
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:PATH=/home/jdk1.8.0_101/bin:/home/jdk1.8.0_101/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/home/hadoop-2.7.3:/home/hadoop-2.7.3/bin/:/root/bin:/home/hadoop-2.7.3:/home/hadoop-2.7.3/bin/:/home/hbase-1.2.2/bin
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF_DIR=/home/hadoop-2.7.3/etc/hadoop
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:XDG_DATA_DIRS=/root/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/root
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/home/hadoop-2.7.3/lib/native
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:LOGNAME=root
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:PWD=/home/hbase-1.2.2
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:SELINUX_USE_CURRENT_RANGE=
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/home/hadoop-2.7.3
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -XX:PermSize=128m -XX:MaxPermSize=128m -Dhbase.log.dir=/home/hbase-1.2.2/logs -Dhbase.log.file=hbase-root-master-master.log -Dhbase.home.dir=/home/hbase-1.2.2 -Dhbase.id.str=root -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop-2.7.3/lib/native -Dhbase.security.logger=INFO,RFAS
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase-root-master.autorestart
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.Z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38;5;9:*.rar=38;5;9:*.alz=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.cab=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.axv=38;5;13:*.anx=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2019-05-04 17:22:24,870 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-root-master-master.log
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/home/jdk1.8.0_101
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:TERM=xterm-256color
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:LANG=de_DE.UTF-8
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=17
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:SELINUX_LEVEL_REQUESTED=
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:SELINUX_ROLE_REQUESTED=
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:YARN_HOME=/home/hadoop-2.7.3
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:HADOOP_HDFS_HOME=/home/hadoop-2.7.3
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:HADOOP_MAPRED_HOME=/hpme/hadoop-2.7.3
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_HOME=/home/hadoop-2.7.3
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=root
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase-root-master.znode
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:SSH_TTY=/dev/pts/4
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=192.168.178.62 53550 22
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-root-master-master
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hbase-1.2.2/logs
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:USER=root
2019-05-04 17:22:24,871 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hbase-1.2.2/conf:/home/jdk1.8.0_101/lib/tools.jar:/home/hbase-1.2.2:/home/hbase-1.2.2/lib/activation-1.1.jar:/home/hbase-1.2.2/lib/antisamy-1.5.3.jar:/home/hbase-1.2.2/lib/aopalliance-1.0.jar:/home/hbase-1.2.2/lib/apacheds-i18n-2.0.0-M15.jar:/home/hbase-1.2.2/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hbase-1.2.2/lib/api-asn1-api-1.0.0-M20.jar:/home/hbase-1.2.2/lib/api-util-1.0.0-M20.jar:/home/hbase-1.2.2/lib/asm-3.1.jar:/home/hbase-1.2.2/lib/avro-1.7.4.jar:/home/hbase-1.2.2/lib/batik-css-1.8.jar:/home/hbase-1.2.2/lib/batik-ext-1.8.jar:/home/hbase-1.2.2/lib/batik-util-1.8.jar:/home/hbase-1.2.2/lib/bsh-core-2.0b4.jar:/home/hbase-1.2.2/lib/commons-beanutils-1.7.0.jar:/home/hbase-1.2.2/lib/commons-beanutils-core-1.8.3.jar:/home/hbase-1.2.2/lib/commons-cli-1.2.jar:/home/hbase-1.2.2/lib/commons-codec-1.9.jar:/home/hbase-1.2.2/lib/commons-collections-3.2.2.jar:/home/hbase-1.2.2/lib/commons-compress-1.4.1.jar:/home/hbase-1.2.2/lib/commons-configuration-1.6.jar:/home/hbase-1.2.2/lib/commons-daemon-1.0.13.jar:/home/hbase-1.2.2/lib/commons-digester-1.8.jar:/home/hbase-1.2.2/lib/commons-el-1.0.jar:/home/hbase-1.2.2/lib/commons-fileupload-1.3.1.jar:/home/hbase-1.2.2/lib/commons-httpclient-3.1.jar:/home/hbase-1.2.2/lib/commons-io-2.4.jar:/home/hbase-1.2.2/lib/commons-lang-2.6.jar:/home/hbase-1.2.2/lib/commons-logging-1.2.jar:/home/hbase-1.2.2/lib/commons-math-2.2.jar:/home/hbase-1.2.2/lib/commons-math3-3.1.1.jar:/home/hbase-1.2.2/lib/commons-net-3.1.jar:/home/hbase-1.2.2/lib/disruptor-3.3.0.jar:/home/hbase-1.2.2/lib/esapi-2.1.0.1.jar:/home/hbase-1.2.2/lib/findbugs-annotations-1.3.9-1.jar:/home/hbase-1.2.2/lib/guava-12.0.1.jar:/home/hbase-1.2.2/lib/guice-3.0.jar:/home/hbase-1.2.2/lib/guice-servlet-3.0.jar:/home/hbase-1.2.2/lib/hadoop-annotations-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-auth-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-hdfs-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-app-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-core-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-api-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-server-common-2.5.1.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-client-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-examples-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-external-blockcache-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop2-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-prefix-tree-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-procedure-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-protocol-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-resource-bundle-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-rest-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-shell-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-thrift-1.2.2.jar:/home/hbase-1.2.2/lib/htrace-core-3.1.0-incubating.jar:/home/hbase-1.2.2/lib/httpclient-4.2.5.jar:/home/hbase-1.2.2/lib/httpcore-4.4.1.jar:/home/hbase-1.2.2/lib/jackson-core-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-jaxrs-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-mapper-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-xc-1.9.13.jar:/home/hbase-1.2.2/lib/jamon-runtime-2.4.1.jar:/home/hbase-1.2.2/lib/jasper-compiler-5.5.23.jar:/home/hbase-1.2.2/lib/jasper-runtime-5.5.23.jar:/home/hbase-1.2.2/lib/javax.inject-1.jar:/home/hbase-1.2.2/lib/java-xmlbuilder-0.4.jar:/home/hbase-1.2.2/lib/jaxb-api-2.2.2.jar:/home/hbase-1.2.2/lib/jaxb-impl-2.2.3-1.jar:/home/hbase-1.2.2/lib/jcodings-1.0.8.jar:/home/hbase-1.2.2/lib/jersey-client-1.9.jar:/home/hbase-1.2.2/lib/jersey-core-1.9.jar:/home/hbase-1.2.2/lib/jersey-guice-1.9.jar:/home/hbase-1.2.2/lib/jersey-json-1.9.jar:/home/hbase-1.2.2/lib/jersey-server-1.9.jar:/home/hbase-1.2.2/lib/jets3t-0.9.0.jar:/home/hbase-1.2.2/lib/jettison-1.3.3.jar:/home/hbase-1.2.2/lib/jetty-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-sslengine-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-util-6.1.26.jar:/home/hbase-1.2.2/lib/joni-2.1.2.jar:/home/hbase-1.2.2/lib/jruby-complete-1.6.8.jar:/home/hbase-1.2.2/lib/jsch-0.1.42.jar:/home/hbase-1.2.2/lib/jsp-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsp-api-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsr305-1.3.9.jar:/home/hbase-1.2.2/lib/junit-4.12.jar:/home/hbase-1.2.2/lib/leveldbjni-all-1.8.jar:/home/hbase-1.2.2/lib/libthrift-0.9.3.jar:/home/hbase-1.2.2/lib/log4j-1.2.17.jar:/home/hbase-1.2.2/lib/metrics-core-2.2.0.jar:/home/hbase-1.2.2/lib/nekohtml-1.9.16.jar:/home/hbase-1.2.2/lib/netty-all-4.0.23.Final.jar:/home/hbase-1.2.2/lib/paranamer-2.3.jar:/home/hbase-1.2.2/lib/protobuf-java-2.5.0.jar:/home/hbase-1.2.2/lib/servlet-api-2.5-6.1.14.jar:/home/hbase-1.2.2/lib/servlet-api-2.5.jar:/home/hbase-1.2.2/lib/slf4j-api-1.7.7.jar:/home/hbase-1.2.2/lib/slf4j-log4j12-1.7.5.jar:/home/hbase-1.2.2/lib/snappy-java-1.0.4.1.jar:/home/hbase-1.2.2/lib/spymemcached-2.11.6.jar:/home/hbase-1.2.2/lib/xalan-2.7.0.jar:/home/hbase-1.2.2/lib/xml-apis-1.3.03.jar:/home/hbase-1.2.2/lib/xml-apis-ext-1.3.04.jar:/home/hbase-1.2.2/lib/xmlenc-0.52.jar:/home/hbase-1.2.2/lib/xom-1.2.5.jar:/home/hbase-1.2.2/lib/xz-1.0.jar:/home/hbase-1.2.2/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/etc/hadoop:/home/hadoop-2.7.3/share/hadoop/common/lib/*:/home/hadoop-2.7.3/share/hadoop/common/*:/home/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/*:/home/hadoop-2.7.3/share/hadoop/hdfs/*:/home/hadoop-2.7.3/share/hadoop/yarn/lib/*:/home/hadoop-2.7.3/share/hadoop/yarn/*:/hpme/hadoop-2.7.3/share/hadoop/mapreduce/*:/home/hadoop-2.7.3/contrib/capacity-scheduler/*.jar
2019-05-04 17:22:24,872 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=192.168.178.62 53550 192.168.178.37 22
2019-05-04 17:22:24,872 INFO  [main] util.ServerCommandLine: env:HOSTNAME=master
2019-05-04 17:22:24,872 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2019-05-04 17:22:24,872 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/0
2019-05-04 17:22:24,872 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2019-05-04 17:22:24,872 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hbase-1.2.2
2019-05-04 17:22:24,872 INFO  [main] util.ServerCommandLine: env:HOME=/root
2019-05-04 17:22:24,872 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2019-05-04 17:22:24,873 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) Client VM, vmVendor=Oracle Corporation, vmVersion=25.101-b13
2019-05-04 17:22:24,873 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -XX:+UseConcMarkSweepGC, -XX:PermSize=128m, -XX:MaxPermSize=128m, -Dhbase.log.dir=/home/hbase-1.2.2/logs, -Dhbase.log.file=hbase-root-master-master.log, -Dhbase.home.dir=/home/hbase-1.2.2, -Dhbase.id.str=root, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop-2.7.3/lib/native, -Dhbase.security.logger=INFO,RFAS]
2019-05-04 17:22:25,069 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-05-04 17:22:25,298 INFO  [main] regionserver.RSRpcServices: master/master/192.168.178.37:16000 server-side HConnection retries=350
2019-05-04 17:22:25,471 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2019-05-04 17:22:25,503 INFO  [main] ipc.RpcServer: master/master/192.168.178.37:16000: started 10 reader(s) listening on port=16000
2019-05-04 17:22:25,598 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2019-05-04 17:22:25,702 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-05-04 17:22:25,702 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2019-05-04 17:22:26,386 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2019-05-04 17:22:26,689 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16000 connecting to ZooKeeper ensemble=localhost:2181
2019-05-04 17:22:26,694 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2019-05-04 17:22:26,694 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=master
2019-05-04 17:22:26,694 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_101
2019-05-04 17:22:26,694 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2019-05-04 17:22:26,694 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/home/jdk1.8.0_101/jre
2019-05-04 17:22:26,694 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hbase-1.2.2/conf:/home/jdk1.8.0_101/lib/tools.jar:/home/hbase-1.2.2:/home/hbase-1.2.2/lib/activation-1.1.jar:/home/hbase-1.2.2/lib/antisamy-1.5.3.jar:/home/hbase-1.2.2/lib/aopalliance-1.0.jar:/home/hbase-1.2.2/lib/apacheds-i18n-2.0.0-M15.jar:/home/hbase-1.2.2/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hbase-1.2.2/lib/api-asn1-api-1.0.0-M20.jar:/home/hbase-1.2.2/lib/api-util-1.0.0-M20.jar:/home/hbase-1.2.2/lib/asm-3.1.jar:/home/hbase-1.2.2/lib/avro-1.7.4.jar:/home/hbase-1.2.2/lib/batik-css-1.8.jar:/home/hbase-1.2.2/lib/batik-ext-1.8.jar:/home/hbase-1.2.2/lib/batik-util-1.8.jar:/home/hbase-1.2.2/lib/bsh-core-2.0b4.jar:/home/hbase-1.2.2/lib/commons-beanutils-1.7.0.jar:/home/hbase-1.2.2/lib/commons-beanutils-core-1.8.3.jar:/home/hbase-1.2.2/lib/commons-cli-1.2.jar:/home/hbase-1.2.2/lib/commons-codec-1.9.jar:/home/hbase-1.2.2/lib/commons-collections-3.2.2.jar:/home/hbase-1.2.2/lib/commons-compress-1.4.1.jar:/home/hbase-1.2.2/lib/commons-configuration-1.6.jar:/home/hbase-1.2.2/lib/commons-daemon-1.0.13.jar:/home/hbase-1.2.2/lib/commons-digester-1.8.jar:/home/hbase-1.2.2/lib/commons-el-1.0.jar:/home/hbase-1.2.2/lib/commons-fileupload-1.3.1.jar:/home/hbase-1.2.2/lib/commons-httpclient-3.1.jar:/home/hbase-1.2.2/lib/commons-io-2.4.jar:/home/hbase-1.2.2/lib/commons-lang-2.6.jar:/home/hbase-1.2.2/lib/commons-logging-1.2.jar:/home/hbase-1.2.2/lib/commons-math-2.2.jar:/home/hbase-1.2.2/lib/commons-math3-3.1.1.jar:/home/hbase-1.2.2/lib/commons-net-3.1.jar:/home/hbase-1.2.2/lib/disruptor-3.3.0.jar:/home/hbase-1.2.2/lib/esapi-2.1.0.1.jar:/home/hbase-1.2.2/lib/findbugs-annotations-1.3.9-1.jar:/home/hbase-1.2.2/lib/guava-12.0.1.jar:/home/hbase-1.2.2/lib/guice-3.0.jar:/home/hbase-1.2.2/lib/guice-servlet-3.0.jar:/home/hbase-1.2.2/lib/hadoop-annotations-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-auth-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-hdfs-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-app-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-core-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-api-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-server-common-2.5.1.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-client-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-examples-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-external-blockcache-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop2-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-prefix-tree-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-procedure-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-protocol-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-resource-bundle-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-rest-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-shell-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-thrift-1.2.2.jar:/home/hbase-1.2.2/lib/htrace-core-3.1.0-incubating.jar:/home/hbase-1.2.2/lib/httpclient-4.2.5.jar:/home/hbase-1.2.2/lib/httpcore-4.4.1.jar:/home/hbase-1.2.2/lib/jackson-core-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-jaxrs-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-mapper-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-xc-1.9.13.jar:/home/hbase-1.2.2/lib/jamon-runtime-2.4.1.jar:/home/hbase-1.2.2/lib/jasper-compiler-5.5.23.jar:/home/hbase-1.2.2/lib/jasper-runtime-5.5.23.jar:/home/hbase-1.2.2/lib/javax.inject-1.jar:/home/hbase-1.2.2/lib/java-xmlbuilder-0.4.jar:/home/hbase-1.2.2/lib/jaxb-api-2.2.2.jar:/home/hbase-1.2.2/lib/jaxb-impl-2.2.3-1.jar:/home/hbase-1.2.2/lib/jcodings-1.0.8.jar:/home/hbase-1.2.2/lib/jersey-client-1.9.jar:/home/hbase-1.2.2/lib/jersey-core-1.9.jar:/home/hbase-1.2.2/lib/jersey-guice-1.9.jar:/home/hbase-1.2.2/lib/jersey-json-1.9.jar:/home/hbase-1.2.2/lib/jersey-server-1.9.jar:/home/hbase-1.2.2/lib/jets3t-0.9.0.jar:/home/hbase-1.2.2/lib/jettison-1.3.3.jar:/home/hbase-1.2.2/lib/jetty-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-sslengine-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-util-6.1.26.jar:/home/hbase-1.2.2/lib/joni-2.1.2.jar:/home/hbase-1.2.2/lib/jruby-complete-1.6.8.jar:/home/hbase-1.2.2/lib/jsch-0.1.42.jar:/home/hbase-1.2.2/lib/jsp-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsp-api-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsr305-1.3.9.jar:/home/hbase-1.2.2/lib/junit-4.12.jar:/home/hbase-1.2.2/lib/leveldbjni-all-1.8.jar:/home/hbase-1.2.2/lib/libthrift-0.9.3.jar:/home/hbase-1.2.2/lib/log4j-1.2.17.jar:/home/hbase-1.2.2/lib/metrics-core-2.2.0.jar:/home/hbase-1.2.2/lib/nekohtml-1.9.16.jar:/home/hbase-1.2.2/lib/netty-all-4.0.23.Final.jar:/home/hbase-1.2.2/lib/paranamer-2.3.jar:/home/hbase-1.2.2/lib/protobuf-java-2.5.0.jar:/home/hbase-1.2.2/lib/servlet-api-2.5-6.1.14.jar:/home/hbase-1.2.2/lib/servlet-api-2.5.jar:/home/hbase-1.2.2/lib/slf4j-api-1.7.7.jar:/home/hbase-1.2.2/lib/slf4j-log4j12-1.7.5.jar:/home/hbase-1.2.2/lib/snappy-java-1.0.4.1.jar:/home/hbase-1.2.2/lib/spymemcached-2.11.6.jar:/home/hbase-1.2.2/lib/xalan-2.7.0.jar:/home/hbase-1.2.2/lib/xml-apis-1.3.03.jar:/home/hbase-1.2.2/lib/xml-apis-ext-1.3.04.jar:/home/hbase-1.2.2/lib/xmlenc-0.52.jar:/home/hbase-1.2.2/lib/xom-1.2.5.jar:/home/hbase-1.2.2/lib/xz-1.0.jar:/home/hbase-1.2.2/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/etc/hadoop:/home/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/hpme/hadoop-2.7.3/share/hadoop/mapreduce/*:/home/hadoop-2.7.3/contrib/capacity-scheduler/*.jar
2019-05-04 17:22:26,694 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop-2.7.3/lib/native
2019-05-04 17:22:26,694 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2019-05-04 17:22:26,694 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2019-05-04 17:22:26,694 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2019-05-04 17:22:26,694 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=i386
2019-05-04 17:22:26,694 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=3.10.0-957.10.1.el7.x86_64
2019-05-04 17:22:26,694 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=root
2019-05-04 17:22:26,694 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/root
2019-05-04 17:22:26,694 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hbase-1.2.2
2019-05-04 17:22:26,709 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=master:160000x0, quorum=localhost:2181, baseZNode=/hbase
2019-05-04 17:22:26,752 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2019-05-04 17:22:26,756 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session
2019-05-04 17:22:26,822 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x16a83706b110000, negotiated timeout = 90000
2019-05-04 17:22:27,055 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2019-05-04 17:22:27,060 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: starting
2019-05-04 17:22:27,900 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-05-04 17:22:27,930 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2019-05-04 17:22:27,939 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2019-05-04 17:22:27,939 INFO  [main] http.HttpServer: Added global filter 'clickjackingprevention' (class=org.apache.hadoop.hbase.http.ClickjackingPreventionFilter)
2019-05-04 17:22:27,961 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2019-05-04 17:22:27,961 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-05-04 17:22:27,961 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-05-04 17:22:28,000 INFO  [main] http.HttpServer: Jetty bound to port 16010
2019-05-04 17:22:28,000 INFO  [main] mortbay.log: jetty-6.1.26
2019-05-04 17:22:28,623 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2019-05-04 17:22:28,627 INFO  [main] master.HMaster: hbase.rootdir=hdfs://master:9000/hbase, hbase.cluster.distributed=true
2019-05-04 17:22:28,649 INFO  [main] master.HMaster: Adding backup master ZNode /hbase/backup-masters/master,16000,1556983345716
2019-05-04 17:22:28,818 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/master,16000,1556983345716 from backup master directory
2019-05-04 17:22:28,835 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Registered Active Master=master,16000,1556983345716
2019-05-04 17:22:28,955 INFO  [master/master/192.168.178.37:16000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x7939bc connecting to ZooKeeper ensemble=localhost:2181
2019-05-04 17:22:28,955 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x7939bc0x0, quorum=localhost:2181, baseZNode=/hbase
2019-05-04 17:22:28,995 FATAL [master:16000.activeMasterManager] master.HMaster: Failed to become active master
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setSafeMode(ClientNamenodeProtocolTranslatorPB.java:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.setSafeMode(DFSClient.java:2264)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:986)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:970)
	at org.apache.hadoop.hbase.util.FSUtils.isInSafeMode(FSUtils.java:525)
	at org.apache.hadoop.hbase.util.FSUtils.waitOnSafeMode(FSUtils.java:971)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:424)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:153)
	at org.apache.hadoop.hbase.master.MasterFileSystem.<init>(MasterFileSystem.java:128)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:652)
	at org.apache.hadoop.hbase.master.HMaster.access$600(HMaster.java:185)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1750)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 29 more
2019-05-04 17:22:29,012 FATAL [master:16000.activeMasterManager] master.HMaster: Unhandled exception. Starting shutdown.
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setSafeMode(ClientNamenodeProtocolTranslatorPB.java:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.setSafeMode(DFSClient.java:2264)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:986)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:970)
	at org.apache.hadoop.hbase.util.FSUtils.isInSafeMode(FSUtils.java:525)
	at org.apache.hadoop.hbase.util.FSUtils.waitOnSafeMode(FSUtils.java:971)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:424)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:153)
	at org.apache.hadoop.hbase.master.MasterFileSystem.<init>(MasterFileSystem.java:128)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:652)
	at org.apache.hadoop.hbase.master.HMaster.access$600(HMaster.java:185)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1750)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 29 more
2019-05-04 17:22:29,012 INFO  [master:16000.activeMasterManager] regionserver.HRegionServer: STOPPED: Unhandled exception. Starting shutdown.
2019-05-04 17:22:28,997 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2019-05-04 17:22:29,014 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2019-05-04 17:22:29,033 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16a83706b110001, negotiated timeout = 90000
2019-05-04 17:22:29,034 INFO  [master/master/192.168.178.37:16000] client.ZooKeeperRegistry: ClusterId read in ZooKeeper is null
2019-05-04 17:22:32,126 INFO  [master/master/192.168.178.37:16000] ipc.RpcServer: Stopping server on 16000
2019-05-04 17:22:32,127 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: stopping
2019-05-04 17:22:32,127 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: Stopping infoServer
2019-05-04 17:22:32,139 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2019-05-04 17:22:32,139 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2019-05-04 17:22:32,172 INFO  [master/master/192.168.178.37:16000] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:16010
2019-05-04 17:22:32,172 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1556983345716
2019-05-04 17:22:32,172 INFO  [master/master/192.168.178.37:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x16a83706b110001
2019-05-04 17:22:32,177 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Session: 0x16a83706b110001 closed
2019-05-04 17:22:32,180 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1556983345716; all regions closed.
2019-05-04 17:22:32,180 INFO  [master/master/192.168.178.37:16000-EventThread] zookeeper.ClientCnxn: EventThread shut down
2019-05-04 17:22:32,180 INFO  [master/master/192.168.178.37:16000] hbase.ChoreService: Chore service for: master,16000,1556983345716 had [] on shutdown
2019-05-04 17:22:32,187 INFO  [master/master/192.168.178.37:16000] ipc.RpcServer: Stopping server on 16000
2019-05-04 17:22:32,196 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Session: 0x16a83706b110000 closed
2019-05-04 17:22:32,197 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1556983345716; zookeeper connection closed.
2019-05-04 17:22:32,197 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: master/master/192.168.178.37:16000 exiting
2019-05-04 17:22:32,197 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
Sa 4. Mai 17:23:18 CEST 2019 Stopping hbase (via master)
Sa 4. Mai 17:23:34 CEST 2019 Starting master on master
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 14923
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 14923
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2019-05-04 17:23:34,560 INFO  [main] util.VersionInfo: HBase 1.2.2
2019-05-04 17:23:34,560 INFO  [main] util.VersionInfo: Source code repository git://asf-dev/home/busbey/projects/hbase revision=3f671c1ead70d249ea4598f1bbcc5151322b3a13
2019-05-04 17:23:34,560 INFO  [main] util.VersionInfo: Compiled by busbey on Fri Jul  1 08:28:55 CDT 2016
2019-05-04 17:23:34,560 INFO  [main] util.VersionInfo: From source with checksum 7ac43c3d2f62f134b2a6aa1a05ad66ac
2019-05-04 17:23:34,900 INFO  [main] util.ServerCommandLine: env:PATH=/home/jdk1.8.0_101/bin:/home/jdk1.8.0_101/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/home/hadoop-2.7.3:/home/hadoop-2.7.3/bin/:/root/bin:/home/hadoop-2.7.3:/home/hadoop-2.7.3/bin/:/home/hbase-1.2.2/bin
2019-05-04 17:23:34,900 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF_DIR=/home/hadoop-2.7.3/etc/hadoop
2019-05-04 17:23:34,900 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2019-05-04 17:23:34,900 INFO  [main] util.ServerCommandLine: env:XDG_DATA_DIRS=/root/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share
2019-05-04 17:23:34,900 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2019-05-04 17:23:34,900 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/root
2019-05-04 17:23:34,900 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/home/hadoop-2.7.3/lib/native
2019-05-04 17:23:34,900 INFO  [main] util.ServerCommandLine: env:LOGNAME=root
2019-05-04 17:23:34,900 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2019-05-04 17:23:34,900 INFO  [main] util.ServerCommandLine: env:PWD=/home/hbase-1.2.2
2019-05-04 17:23:34,900 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2019-05-04 17:23:34,900 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2019-05-04 17:23:34,900 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2019-05-04 17:23:34,900 INFO  [main] util.ServerCommandLine: env:SELINUX_USE_CURRENT_RANGE=
2019-05-04 17:23:34,900 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/home/hadoop-2.7.3
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -XX:PermSize=128m -XX:MaxPermSize=128m -Dhbase.log.dir=/home/hbase-1.2.2/logs -Dhbase.log.file=hbase-root-master-master.log -Dhbase.home.dir=/home/hbase-1.2.2 -Dhbase.id.str=root -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop-2.7.3/lib/native -Dhbase.security.logger=INFO,RFAS
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase-root-master.autorestart
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.Z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38;5;9:*.rar=38;5;9:*.alz=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.cab=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.axv=38;5;13:*.anx=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-root-master-master.log
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/home/jdk1.8.0_101
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:TERM=xterm-256color
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:LANG=de_DE.UTF-8
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=17
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:SELINUX_LEVEL_REQUESTED=
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:SELINUX_ROLE_REQUESTED=
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:YARN_HOME=/home/hadoop-2.7.3
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:HADOOP_HDFS_HOME=/home/hadoop-2.7.3
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:HADOOP_MAPRED_HOME=/hpme/hadoop-2.7.3
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_HOME=/home/hadoop-2.7.3
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=root
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase-root-master.znode
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:SSH_TTY=/dev/pts/4
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=192.168.178.62 53550 22
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-root-master-master
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hbase-1.2.2/logs
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:USER=root
2019-05-04 17:23:34,901 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hbase-1.2.2/conf:/home/jdk1.8.0_101/lib/tools.jar:/home/hbase-1.2.2:/home/hbase-1.2.2/lib/activation-1.1.jar:/home/hbase-1.2.2/lib/antisamy-1.5.3.jar:/home/hbase-1.2.2/lib/aopalliance-1.0.jar:/home/hbase-1.2.2/lib/apacheds-i18n-2.0.0-M15.jar:/home/hbase-1.2.2/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hbase-1.2.2/lib/api-asn1-api-1.0.0-M20.jar:/home/hbase-1.2.2/lib/api-util-1.0.0-M20.jar:/home/hbase-1.2.2/lib/asm-3.1.jar:/home/hbase-1.2.2/lib/avro-1.7.4.jar:/home/hbase-1.2.2/lib/batik-css-1.8.jar:/home/hbase-1.2.2/lib/batik-ext-1.8.jar:/home/hbase-1.2.2/lib/batik-util-1.8.jar:/home/hbase-1.2.2/lib/bsh-core-2.0b4.jar:/home/hbase-1.2.2/lib/commons-beanutils-1.7.0.jar:/home/hbase-1.2.2/lib/commons-beanutils-core-1.8.3.jar:/home/hbase-1.2.2/lib/commons-cli-1.2.jar:/home/hbase-1.2.2/lib/commons-codec-1.9.jar:/home/hbase-1.2.2/lib/commons-collections-3.2.2.jar:/home/hbase-1.2.2/lib/commons-compress-1.4.1.jar:/home/hbase-1.2.2/lib/commons-configuration-1.6.jar:/home/hbase-1.2.2/lib/commons-daemon-1.0.13.jar:/home/hbase-1.2.2/lib/commons-digester-1.8.jar:/home/hbase-1.2.2/lib/commons-el-1.0.jar:/home/hbase-1.2.2/lib/commons-fileupload-1.3.1.jar:/home/hbase-1.2.2/lib/commons-httpclient-3.1.jar:/home/hbase-1.2.2/lib/commons-io-2.4.jar:/home/hbase-1.2.2/lib/commons-lang-2.6.jar:/home/hbase-1.2.2/lib/commons-logging-1.2.jar:/home/hbase-1.2.2/lib/commons-math-2.2.jar:/home/hbase-1.2.2/lib/commons-math3-3.1.1.jar:/home/hbase-1.2.2/lib/commons-net-3.1.jar:/home/hbase-1.2.2/lib/disruptor-3.3.0.jar:/home/hbase-1.2.2/lib/esapi-2.1.0.1.jar:/home/hbase-1.2.2/lib/findbugs-annotations-1.3.9-1.jar:/home/hbase-1.2.2/lib/guava-12.0.1.jar:/home/hbase-1.2.2/lib/guice-3.0.jar:/home/hbase-1.2.2/lib/guice-servlet-3.0.jar:/home/hbase-1.2.2/lib/hadoop-annotations-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-auth-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-hdfs-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-app-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-core-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-api-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-server-common-2.5.1.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-client-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-examples-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-external-blockcache-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop2-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-prefix-tree-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-procedure-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-protocol-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-resource-bundle-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-rest-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-shell-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-thrift-1.2.2.jar:/home/hbase-1.2.2/lib/htrace-core-3.1.0-incubating.jar:/home/hbase-1.2.2/lib/httpclient-4.2.5.jar:/home/hbase-1.2.2/lib/httpcore-4.4.1.jar:/home/hbase-1.2.2/lib/jackson-core-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-jaxrs-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-mapper-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-xc-1.9.13.jar:/home/hbase-1.2.2/lib/jamon-runtime-2.4.1.jar:/home/hbase-1.2.2/lib/jasper-compiler-5.5.23.jar:/home/hbase-1.2.2/lib/jasper-runtime-5.5.23.jar:/home/hbase-1.2.2/lib/javax.inject-1.jar:/home/hbase-1.2.2/lib/java-xmlbuilder-0.4.jar:/home/hbase-1.2.2/lib/jaxb-api-2.2.2.jar:/home/hbase-1.2.2/lib/jaxb-impl-2.2.3-1.jar:/home/hbase-1.2.2/lib/jcodings-1.0.8.jar:/home/hbase-1.2.2/lib/jersey-client-1.9.jar:/home/hbase-1.2.2/lib/jersey-core-1.9.jar:/home/hbase-1.2.2/lib/jersey-guice-1.9.jar:/home/hbase-1.2.2/lib/jersey-json-1.9.jar:/home/hbase-1.2.2/lib/jersey-server-1.9.jar:/home/hbase-1.2.2/lib/jets3t-0.9.0.jar:/home/hbase-1.2.2/lib/jettison-1.3.3.jar:/home/hbase-1.2.2/lib/jetty-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-sslengine-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-util-6.1.26.jar:/home/hbase-1.2.2/lib/joni-2.1.2.jar:/home/hbase-1.2.2/lib/jruby-complete-1.6.8.jar:/home/hbase-1.2.2/lib/jsch-0.1.42.jar:/home/hbase-1.2.2/lib/jsp-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsp-api-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsr305-1.3.9.jar:/home/hbase-1.2.2/lib/junit-4.12.jar:/home/hbase-1.2.2/lib/leveldbjni-all-1.8.jar:/home/hbase-1.2.2/lib/libthrift-0.9.3.jar:/home/hbase-1.2.2/lib/log4j-1.2.17.jar:/home/hbase-1.2.2/lib/metrics-core-2.2.0.jar:/home/hbase-1.2.2/lib/nekohtml-1.9.16.jar:/home/hbase-1.2.2/lib/netty-all-4.0.23.Final.jar:/home/hbase-1.2.2/lib/paranamer-2.3.jar:/home/hbase-1.2.2/lib/protobuf-java-2.5.0.jar:/home/hbase-1.2.2/lib/servlet-api-2.5-6.1.14.jar:/home/hbase-1.2.2/lib/servlet-api-2.5.jar:/home/hbase-1.2.2/lib/slf4j-api-1.7.7.jar:/home/hbase-1.2.2/lib/slf4j-log4j12-1.7.5.jar:/home/hbase-1.2.2/lib/snappy-java-1.0.4.1.jar:/home/hbase-1.2.2/lib/spymemcached-2.11.6.jar:/home/hbase-1.2.2/lib/xalan-2.7.0.jar:/home/hbase-1.2.2/lib/xml-apis-1.3.03.jar:/home/hbase-1.2.2/lib/xml-apis-ext-1.3.04.jar:/home/hbase-1.2.2/lib/xmlenc-0.52.jar:/home/hbase-1.2.2/lib/xom-1.2.5.jar:/home/hbase-1.2.2/lib/xz-1.0.jar:/home/hbase-1.2.2/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/etc/hadoop:/home/hadoop-2.7.3/share/hadoop/common/lib/*:/home/hadoop-2.7.3/share/hadoop/common/*:/home/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/*:/home/hadoop-2.7.3/share/hadoop/hdfs/*:/home/hadoop-2.7.3/share/hadoop/yarn/lib/*:/home/hadoop-2.7.3/share/hadoop/yarn/*:/hpme/hadoop-2.7.3/share/hadoop/mapreduce/*:/home/hadoop-2.7.3/contrib/capacity-scheduler/*.jar
2019-05-04 17:23:34,902 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=192.168.178.62 53550 192.168.178.37 22
2019-05-04 17:23:34,902 INFO  [main] util.ServerCommandLine: env:HOSTNAME=master
2019-05-04 17:23:34,902 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2019-05-04 17:23:34,902 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/0
2019-05-04 17:23:34,902 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2019-05-04 17:23:34,902 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hbase-1.2.2
2019-05-04 17:23:34,902 INFO  [main] util.ServerCommandLine: env:HOME=/root
2019-05-04 17:23:34,902 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2019-05-04 17:23:34,903 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) Client VM, vmVendor=Oracle Corporation, vmVersion=25.101-b13
2019-05-04 17:23:34,903 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -XX:+UseConcMarkSweepGC, -XX:PermSize=128m, -XX:MaxPermSize=128m, -Dhbase.log.dir=/home/hbase-1.2.2/logs, -Dhbase.log.file=hbase-root-master-master.log, -Dhbase.home.dir=/home/hbase-1.2.2, -Dhbase.id.str=root, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop-2.7.3/lib/native, -Dhbase.security.logger=INFO,RFAS]
2019-05-04 17:23:35,066 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-05-04 17:23:35,292 INFO  [main] regionserver.RSRpcServices: master/master/192.168.178.37:16000 server-side HConnection retries=350
2019-05-04 17:23:35,460 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2019-05-04 17:23:35,490 INFO  [main] ipc.RpcServer: master/master/192.168.178.37:16000: started 10 reader(s) listening on port=16000
2019-05-04 17:23:35,588 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2019-05-04 17:23:35,662 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-05-04 17:23:35,662 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2019-05-04 17:23:36,097 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2019-05-04 17:23:36,241 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16000 connecting to ZooKeeper ensemble=localhost:2181
2019-05-04 17:23:36,248 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2019-05-04 17:23:36,248 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=master
2019-05-04 17:23:36,248 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_101
2019-05-04 17:23:36,248 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2019-05-04 17:23:36,248 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/home/jdk1.8.0_101/jre
2019-05-04 17:23:36,249 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hbase-1.2.2/conf:/home/jdk1.8.0_101/lib/tools.jar:/home/hbase-1.2.2:/home/hbase-1.2.2/lib/activation-1.1.jar:/home/hbase-1.2.2/lib/antisamy-1.5.3.jar:/home/hbase-1.2.2/lib/aopalliance-1.0.jar:/home/hbase-1.2.2/lib/apacheds-i18n-2.0.0-M15.jar:/home/hbase-1.2.2/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hbase-1.2.2/lib/api-asn1-api-1.0.0-M20.jar:/home/hbase-1.2.2/lib/api-util-1.0.0-M20.jar:/home/hbase-1.2.2/lib/asm-3.1.jar:/home/hbase-1.2.2/lib/avro-1.7.4.jar:/home/hbase-1.2.2/lib/batik-css-1.8.jar:/home/hbase-1.2.2/lib/batik-ext-1.8.jar:/home/hbase-1.2.2/lib/batik-util-1.8.jar:/home/hbase-1.2.2/lib/bsh-core-2.0b4.jar:/home/hbase-1.2.2/lib/commons-beanutils-1.7.0.jar:/home/hbase-1.2.2/lib/commons-beanutils-core-1.8.3.jar:/home/hbase-1.2.2/lib/commons-cli-1.2.jar:/home/hbase-1.2.2/lib/commons-codec-1.9.jar:/home/hbase-1.2.2/lib/commons-collections-3.2.2.jar:/home/hbase-1.2.2/lib/commons-compress-1.4.1.jar:/home/hbase-1.2.2/lib/commons-configuration-1.6.jar:/home/hbase-1.2.2/lib/commons-daemon-1.0.13.jar:/home/hbase-1.2.2/lib/commons-digester-1.8.jar:/home/hbase-1.2.2/lib/commons-el-1.0.jar:/home/hbase-1.2.2/lib/commons-fileupload-1.3.1.jar:/home/hbase-1.2.2/lib/commons-httpclient-3.1.jar:/home/hbase-1.2.2/lib/commons-io-2.4.jar:/home/hbase-1.2.2/lib/commons-lang-2.6.jar:/home/hbase-1.2.2/lib/commons-logging-1.2.jar:/home/hbase-1.2.2/lib/commons-math-2.2.jar:/home/hbase-1.2.2/lib/commons-math3-3.1.1.jar:/home/hbase-1.2.2/lib/commons-net-3.1.jar:/home/hbase-1.2.2/lib/disruptor-3.3.0.jar:/home/hbase-1.2.2/lib/esapi-2.1.0.1.jar:/home/hbase-1.2.2/lib/findbugs-annotations-1.3.9-1.jar:/home/hbase-1.2.2/lib/guava-12.0.1.jar:/home/hbase-1.2.2/lib/guice-3.0.jar:/home/hbase-1.2.2/lib/guice-servlet-3.0.jar:/home/hbase-1.2.2/lib/hadoop-annotations-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-auth-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-hdfs-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-app-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-core-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-api-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-server-common-2.5.1.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-client-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-examples-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-external-blockcache-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop2-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-prefix-tree-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-procedure-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-protocol-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-resource-bundle-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-rest-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-shell-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-thrift-1.2.2.jar:/home/hbase-1.2.2/lib/htrace-core-3.1.0-incubating.jar:/home/hbase-1.2.2/lib/httpclient-4.2.5.jar:/home/hbase-1.2.2/lib/httpcore-4.4.1.jar:/home/hbase-1.2.2/lib/jackson-core-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-jaxrs-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-mapper-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-xc-1.9.13.jar:/home/hbase-1.2.2/lib/jamon-runtime-2.4.1.jar:/home/hbase-1.2.2/lib/jasper-compiler-5.5.23.jar:/home/hbase-1.2.2/lib/jasper-runtime-5.5.23.jar:/home/hbase-1.2.2/lib/javax.inject-1.jar:/home/hbase-1.2.2/lib/java-xmlbuilder-0.4.jar:/home/hbase-1.2.2/lib/jaxb-api-2.2.2.jar:/home/hbase-1.2.2/lib/jaxb-impl-2.2.3-1.jar:/home/hbase-1.2.2/lib/jcodings-1.0.8.jar:/home/hbase-1.2.2/lib/jersey-client-1.9.jar:/home/hbase-1.2.2/lib/jersey-core-1.9.jar:/home/hbase-1.2.2/lib/jersey-guice-1.9.jar:/home/hbase-1.2.2/lib/jersey-json-1.9.jar:/home/hbase-1.2.2/lib/jersey-server-1.9.jar:/home/hbase-1.2.2/lib/jets3t-0.9.0.jar:/home/hbase-1.2.2/lib/jettison-1.3.3.jar:/home/hbase-1.2.2/lib/jetty-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-sslengine-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-util-6.1.26.jar:/home/hbase-1.2.2/lib/joni-2.1.2.jar:/home/hbase-1.2.2/lib/jruby-complete-1.6.8.jar:/home/hbase-1.2.2/lib/jsch-0.1.42.jar:/home/hbase-1.2.2/lib/jsp-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsp-api-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsr305-1.3.9.jar:/home/hbase-1.2.2/lib/junit-4.12.jar:/home/hbase-1.2.2/lib/leveldbjni-all-1.8.jar:/home/hbase-1.2.2/lib/libthrift-0.9.3.jar:/home/hbase-1.2.2/lib/log4j-1.2.17.jar:/home/hbase-1.2.2/lib/metrics-core-2.2.0.jar:/home/hbase-1.2.2/lib/nekohtml-1.9.16.jar:/home/hbase-1.2.2/lib/netty-all-4.0.23.Final.jar:/home/hbase-1.2.2/lib/paranamer-2.3.jar:/home/hbase-1.2.2/lib/protobuf-java-2.5.0.jar:/home/hbase-1.2.2/lib/servlet-api-2.5-6.1.14.jar:/home/hbase-1.2.2/lib/servlet-api-2.5.jar:/home/hbase-1.2.2/lib/slf4j-api-1.7.7.jar:/home/hbase-1.2.2/lib/slf4j-log4j12-1.7.5.jar:/home/hbase-1.2.2/lib/snappy-java-1.0.4.1.jar:/home/hbase-1.2.2/lib/spymemcached-2.11.6.jar:/home/hbase-1.2.2/lib/xalan-2.7.0.jar:/home/hbase-1.2.2/lib/xml-apis-1.3.03.jar:/home/hbase-1.2.2/lib/xml-apis-ext-1.3.04.jar:/home/hbase-1.2.2/lib/xmlenc-0.52.jar:/home/hbase-1.2.2/lib/xom-1.2.5.jar:/home/hbase-1.2.2/lib/xz-1.0.jar:/home/hbase-1.2.2/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/etc/hadoop:/home/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/hpme/hadoop-2.7.3/share/hadoop/mapreduce/*:/home/hadoop-2.7.3/contrib/capacity-scheduler/*.jar
2019-05-04 17:23:36,249 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop-2.7.3/lib/native
2019-05-04 17:23:36,249 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2019-05-04 17:23:36,249 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2019-05-04 17:23:36,249 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2019-05-04 17:23:36,249 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=i386
2019-05-04 17:23:36,249 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=3.10.0-957.10.1.el7.x86_64
2019-05-04 17:23:36,249 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=root
2019-05-04 17:23:36,249 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/root
2019-05-04 17:23:36,249 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hbase-1.2.2
2019-05-04 17:23:36,252 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=master:160000x0, quorum=localhost:2181, baseZNode=/hbase
2019-05-04 17:23:36,265 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2019-05-04 17:23:36,269 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2019-05-04 17:23:36,295 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16a83717c3a0000, negotiated timeout = 90000
2019-05-04 17:23:36,337 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2019-05-04 17:23:36,337 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: starting
2019-05-04 17:23:36,420 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-05-04 17:23:36,424 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2019-05-04 17:23:36,431 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2019-05-04 17:23:36,431 INFO  [main] http.HttpServer: Added global filter 'clickjackingprevention' (class=org.apache.hadoop.hbase.http.ClickjackingPreventionFilter)
2019-05-04 17:23:36,435 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2019-05-04 17:23:36,435 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-05-04 17:23:36,435 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-05-04 17:23:36,448 INFO  [main] http.HttpServer: Jetty bound to port 16010
2019-05-04 17:23:36,448 INFO  [main] mortbay.log: jetty-6.1.26
2019-05-04 17:23:36,719 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2019-05-04 17:23:36,723 INFO  [main] master.HMaster: hbase.rootdir=hdfs://master:9000/hbase, hbase.cluster.distributed=true
2019-05-04 17:23:36,733 INFO  [main] master.HMaster: Adding backup master ZNode /hbase/backup-masters/master,16000,1556983415676
2019-05-04 17:23:36,829 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/master,16000,1556983415676 from backup master directory
2019-05-04 17:23:36,849 INFO  [master/master/192.168.178.37:16000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x51bfba connecting to ZooKeeper ensemble=localhost:2181
2019-05-04 17:23:36,849 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x51bfba0x0, quorum=localhost:2181, baseZNode=/hbase
2019-05-04 17:23:36,851 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Registered Active Master=master,16000,1556983415676
2019-05-04 17:23:36,854 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2019-05-04 17:23:36,855 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2019-05-04 17:23:36,857 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16a83717c3a0001, negotiated timeout = 90000
2019-05-04 17:23:36,858 INFO  [master/master/192.168.178.37:16000] client.ZooKeeperRegistry: ClusterId read in ZooKeeper is null
2019-05-04 17:23:36,919 FATAL [master:16000.activeMasterManager] master.HMaster: Failed to become active master
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setSafeMode(ClientNamenodeProtocolTranslatorPB.java:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.setSafeMode(DFSClient.java:2264)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:986)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:970)
	at org.apache.hadoop.hbase.util.FSUtils.isInSafeMode(FSUtils.java:525)
	at org.apache.hadoop.hbase.util.FSUtils.waitOnSafeMode(FSUtils.java:971)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:424)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:153)
	at org.apache.hadoop.hbase.master.MasterFileSystem.<init>(MasterFileSystem.java:128)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:652)
	at org.apache.hadoop.hbase.master.HMaster.access$600(HMaster.java:185)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1750)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 29 more
2019-05-04 17:23:36,924 FATAL [master:16000.activeMasterManager] master.HMaster: Unhandled exception. Starting shutdown.
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setSafeMode(ClientNamenodeProtocolTranslatorPB.java:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.setSafeMode(DFSClient.java:2264)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:986)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:970)
	at org.apache.hadoop.hbase.util.FSUtils.isInSafeMode(FSUtils.java:525)
	at org.apache.hadoop.hbase.util.FSUtils.waitOnSafeMode(FSUtils.java:971)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:424)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:153)
	at org.apache.hadoop.hbase.master.MasterFileSystem.<init>(MasterFileSystem.java:128)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:652)
	at org.apache.hadoop.hbase.master.HMaster.access$600(HMaster.java:185)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1750)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 29 more
2019-05-04 17:23:36,924 INFO  [master:16000.activeMasterManager] regionserver.HRegionServer: STOPPED: Unhandled exception. Starting shutdown.
2019-05-04 17:23:39,979 INFO  [master/master/192.168.178.37:16000] ipc.RpcServer: Stopping server on 16000
2019-05-04 17:23:39,979 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: stopping
2019-05-04 17:23:39,980 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: Stopping infoServer
2019-05-04 17:23:39,992 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2019-05-04 17:23:39,992 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2019-05-04 17:23:40,025 INFO  [master/master/192.168.178.37:16000] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:16010
2019-05-04 17:23:40,026 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1556983415676
2019-05-04 17:23:40,026 INFO  [master/master/192.168.178.37:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x16a83717c3a0001
2019-05-04 17:23:40,031 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Session: 0x16a83717c3a0001 closed
2019-05-04 17:23:40,033 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1556983415676; all regions closed.
2019-05-04 17:23:40,033 INFO  [master/master/192.168.178.37:16000-EventThread] zookeeper.ClientCnxn: EventThread shut down
2019-05-04 17:23:40,033 INFO  [master/master/192.168.178.37:16000] hbase.ChoreService: Chore service for: master,16000,1556983415676 had [] on shutdown
2019-05-04 17:23:40,039 INFO  [master/master/192.168.178.37:16000] ipc.RpcServer: Stopping server on 16000
2019-05-04 17:23:40,042 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Session: 0x16a83717c3a0000 closed
2019-05-04 17:23:40,042 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1556983415676; zookeeper connection closed.
2019-05-04 17:23:40,042 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: master/master/192.168.178.37:16000 exiting
2019-05-04 17:23:40,042 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
Sa 4. Mai 17:26:26 CEST 2019 Stopping hbase (via master)
Sa 4. Mai 17:26:58 CEST 2019 Starting master on master
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 14923
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 14923
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2019-05-04 17:26:58,780 INFO  [main] util.VersionInfo: HBase 1.2.2
2019-05-04 17:26:58,781 INFO  [main] util.VersionInfo: Source code repository git://asf-dev/home/busbey/projects/hbase revision=3f671c1ead70d249ea4598f1bbcc5151322b3a13
2019-05-04 17:26:58,781 INFO  [main] util.VersionInfo: Compiled by busbey on Fri Jul  1 08:28:55 CDT 2016
2019-05-04 17:26:58,781 INFO  [main] util.VersionInfo: From source with checksum 7ac43c3d2f62f134b2a6aa1a05ad66ac
2019-05-04 17:26:59,119 INFO  [main] util.ServerCommandLine: env:PATH=/home/jdk1.8.0_101/bin:/home/jdk1.8.0_101/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/home/hadoop-2.7.3:/home/hadoop-2.7.3/bin/:/root/bin:/home/hadoop-2.7.3:/home/hadoop-2.7.3/bin/:/home/hbase-1.2.2/bin
2019-05-04 17:26:59,119 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF_DIR=/home/hadoop-2.7.3/etc/hadoop
2019-05-04 17:26:59,119 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2019-05-04 17:26:59,119 INFO  [main] util.ServerCommandLine: env:XDG_DATA_DIRS=/root/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share
2019-05-04 17:26:59,119 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2019-05-04 17:26:59,119 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/root
2019-05-04 17:26:59,119 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/home/hadoop-2.7.3/lib/native
2019-05-04 17:26:59,119 INFO  [main] util.ServerCommandLine: env:LOGNAME=root
2019-05-04 17:26:59,119 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2019-05-04 17:26:59,119 INFO  [main] util.ServerCommandLine: env:PWD=/home/hbase-1.2.2
2019-05-04 17:26:59,119 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2019-05-04 17:26:59,119 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2019-05-04 17:26:59,119 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2019-05-04 17:26:59,119 INFO  [main] util.ServerCommandLine: env:SELINUX_USE_CURRENT_RANGE=
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/home/hadoop-2.7.3
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -XX:PermSize=128m -XX:MaxPermSize=128m -Dhbase.log.dir=/home/hbase-1.2.2/logs -Dhbase.log.file=hbase-root-master-master.log -Dhbase.home.dir=/home/hbase-1.2.2 -Dhbase.id.str=root -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop-2.7.3/lib/native -Dhbase.security.logger=INFO,RFAS
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase-root-master.autorestart
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.Z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38;5;9:*.rar=38;5;9:*.alz=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.cab=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.axv=38;5;13:*.anx=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-root-master-master.log
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/home/jdk1.8.0_101
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:TERM=xterm-256color
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:LANG=de_DE.UTF-8
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=17
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:SELINUX_LEVEL_REQUESTED=
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:SELINUX_ROLE_REQUESTED=
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:YARN_HOME=/home/hadoop-2.7.3
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HADOOP_HDFS_HOME=/home/hadoop-2.7.3
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HADOOP_MAPRED_HOME=/hpme/hadoop-2.7.3
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_HOME=/home/hadoop-2.7.3
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=root
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase-root-master.znode
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:SSH_TTY=/dev/pts/4
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=192.168.178.62 53550 22
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-root-master-master
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hbase-1.2.2/logs
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:USER=root
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hbase-1.2.2/conf:/home/jdk1.8.0_101/lib/tools.jar:/home/hbase-1.2.2:/home/hbase-1.2.2/lib/activation-1.1.jar:/home/hbase-1.2.2/lib/antisamy-1.5.3.jar:/home/hbase-1.2.2/lib/aopalliance-1.0.jar:/home/hbase-1.2.2/lib/apacheds-i18n-2.0.0-M15.jar:/home/hbase-1.2.2/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hbase-1.2.2/lib/api-asn1-api-1.0.0-M20.jar:/home/hbase-1.2.2/lib/api-util-1.0.0-M20.jar:/home/hbase-1.2.2/lib/asm-3.1.jar:/home/hbase-1.2.2/lib/avro-1.7.4.jar:/home/hbase-1.2.2/lib/batik-css-1.8.jar:/home/hbase-1.2.2/lib/batik-ext-1.8.jar:/home/hbase-1.2.2/lib/batik-util-1.8.jar:/home/hbase-1.2.2/lib/bsh-core-2.0b4.jar:/home/hbase-1.2.2/lib/commons-beanutils-1.7.0.jar:/home/hbase-1.2.2/lib/commons-beanutils-core-1.8.3.jar:/home/hbase-1.2.2/lib/commons-cli-1.2.jar:/home/hbase-1.2.2/lib/commons-codec-1.9.jar:/home/hbase-1.2.2/lib/commons-collections-3.2.2.jar:/home/hbase-1.2.2/lib/commons-compress-1.4.1.jar:/home/hbase-1.2.2/lib/commons-configuration-1.6.jar:/home/hbase-1.2.2/lib/commons-daemon-1.0.13.jar:/home/hbase-1.2.2/lib/commons-digester-1.8.jar:/home/hbase-1.2.2/lib/commons-el-1.0.jar:/home/hbase-1.2.2/lib/commons-fileupload-1.3.1.jar:/home/hbase-1.2.2/lib/commons-httpclient-3.1.jar:/home/hbase-1.2.2/lib/commons-io-2.4.jar:/home/hbase-1.2.2/lib/commons-lang-2.6.jar:/home/hbase-1.2.2/lib/commons-logging-1.2.jar:/home/hbase-1.2.2/lib/commons-math-2.2.jar:/home/hbase-1.2.2/lib/commons-math3-3.1.1.jar:/home/hbase-1.2.2/lib/commons-net-3.1.jar:/home/hbase-1.2.2/lib/disruptor-3.3.0.jar:/home/hbase-1.2.2/lib/esapi-2.1.0.1.jar:/home/hbase-1.2.2/lib/findbugs-annotations-1.3.9-1.jar:/home/hbase-1.2.2/lib/guava-12.0.1.jar:/home/hbase-1.2.2/lib/guice-3.0.jar:/home/hbase-1.2.2/lib/guice-servlet-3.0.jar:/home/hbase-1.2.2/lib/hadoop-annotations-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-auth-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-hdfs-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-app-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-core-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-api-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-server-common-2.5.1.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-client-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-examples-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-external-blockcache-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop2-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-prefix-tree-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-procedure-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-protocol-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-resource-bundle-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-rest-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-shell-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-thrift-1.2.2.jar:/home/hbase-1.2.2/lib/htrace-core-3.1.0-incubating.jar:/home/hbase-1.2.2/lib/httpclient-4.2.5.jar:/home/hbase-1.2.2/lib/httpcore-4.4.1.jar:/home/hbase-1.2.2/lib/jackson-core-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-jaxrs-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-mapper-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-xc-1.9.13.jar:/home/hbase-1.2.2/lib/jamon-runtime-2.4.1.jar:/home/hbase-1.2.2/lib/jasper-compiler-5.5.23.jar:/home/hbase-1.2.2/lib/jasper-runtime-5.5.23.jar:/home/hbase-1.2.2/lib/javax.inject-1.jar:/home/hbase-1.2.2/lib/java-xmlbuilder-0.4.jar:/home/hbase-1.2.2/lib/jaxb-api-2.2.2.jar:/home/hbase-1.2.2/lib/jaxb-impl-2.2.3-1.jar:/home/hbase-1.2.2/lib/jcodings-1.0.8.jar:/home/hbase-1.2.2/lib/jersey-client-1.9.jar:/home/hbase-1.2.2/lib/jersey-core-1.9.jar:/home/hbase-1.2.2/lib/jersey-guice-1.9.jar:/home/hbase-1.2.2/lib/jersey-json-1.9.jar:/home/hbase-1.2.2/lib/jersey-server-1.9.jar:/home/hbase-1.2.2/lib/jets3t-0.9.0.jar:/home/hbase-1.2.2/lib/jettison-1.3.3.jar:/home/hbase-1.2.2/lib/jetty-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-sslengine-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-util-6.1.26.jar:/home/hbase-1.2.2/lib/joni-2.1.2.jar:/home/hbase-1.2.2/lib/jruby-complete-1.6.8.jar:/home/hbase-1.2.2/lib/jsch-0.1.42.jar:/home/hbase-1.2.2/lib/jsp-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsp-api-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsr305-1.3.9.jar:/home/hbase-1.2.2/lib/junit-4.12.jar:/home/hbase-1.2.2/lib/leveldbjni-all-1.8.jar:/home/hbase-1.2.2/lib/libthrift-0.9.3.jar:/home/hbase-1.2.2/lib/log4j-1.2.17.jar:/home/hbase-1.2.2/lib/metrics-core-2.2.0.jar:/home/hbase-1.2.2/lib/nekohtml-1.9.16.jar:/home/hbase-1.2.2/lib/netty-all-4.0.23.Final.jar:/home/hbase-1.2.2/lib/paranamer-2.3.jar:/home/hbase-1.2.2/lib/protobuf-java-2.5.0.jar:/home/hbase-1.2.2/lib/servlet-api-2.5-6.1.14.jar:/home/hbase-1.2.2/lib/servlet-api-2.5.jar:/home/hbase-1.2.2/lib/slf4j-api-1.7.7.jar:/home/hbase-1.2.2/lib/slf4j-log4j12-1.7.5.jar:/home/hbase-1.2.2/lib/snappy-java-1.0.4.1.jar:/home/hbase-1.2.2/lib/spymemcached-2.11.6.jar:/home/hbase-1.2.2/lib/xalan-2.7.0.jar:/home/hbase-1.2.2/lib/xml-apis-1.3.03.jar:/home/hbase-1.2.2/lib/xml-apis-ext-1.3.04.jar:/home/hbase-1.2.2/lib/xmlenc-0.52.jar:/home/hbase-1.2.2/lib/xom-1.2.5.jar:/home/hbase-1.2.2/lib/xz-1.0.jar:/home/hbase-1.2.2/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/etc/hadoop:/home/hadoop-2.7.3/share/hadoop/common/lib/*:/home/hadoop-2.7.3/share/hadoop/common/*:/home/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/*:/home/hadoop-2.7.3/share/hadoop/hdfs/*:/home/hadoop-2.7.3/share/hadoop/yarn/lib/*:/home/hadoop-2.7.3/share/hadoop/yarn/*:/hpme/hadoop-2.7.3/share/hadoop/mapreduce/*:/home/hadoop-2.7.3/contrib/capacity-scheduler/*.jar
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=192.168.178.62 53550 192.168.178.37 22
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HOSTNAME=master
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/0
2019-05-04 17:26:59,120 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2019-05-04 17:26:59,121 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hbase-1.2.2
2019-05-04 17:26:59,121 INFO  [main] util.ServerCommandLine: env:HOME=/root
2019-05-04 17:26:59,121 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2019-05-04 17:26:59,122 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) Client VM, vmVendor=Oracle Corporation, vmVersion=25.101-b13
2019-05-04 17:26:59,122 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -XX:+UseConcMarkSweepGC, -XX:PermSize=128m, -XX:MaxPermSize=128m, -Dhbase.log.dir=/home/hbase-1.2.2/logs, -Dhbase.log.file=hbase-root-master-master.log, -Dhbase.home.dir=/home/hbase-1.2.2, -Dhbase.id.str=root, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop-2.7.3/lib/native, -Dhbase.security.logger=INFO,RFAS]
2019-05-04 17:26:59,282 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-05-04 17:26:59,502 INFO  [main] regionserver.RSRpcServices: master/master/192.168.178.37:16000 server-side HConnection retries=350
2019-05-04 17:26:59,676 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2019-05-04 17:26:59,705 INFO  [main] ipc.RpcServer: master/master/192.168.178.37:16000: started 10 reader(s) listening on port=16000
2019-05-04 17:26:59,802 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2019-05-04 17:26:59,870 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-05-04 17:26:59,870 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2019-05-04 17:27:00,315 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2019-05-04 17:27:00,464 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16000 connecting to ZooKeeper ensemble=localhost:2181
2019-05-04 17:27:00,470 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2019-05-04 17:27:00,471 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=master
2019-05-04 17:27:00,471 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_101
2019-05-04 17:27:00,471 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2019-05-04 17:27:00,471 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/home/jdk1.8.0_101/jre
2019-05-04 17:27:00,471 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hbase-1.2.2/conf:/home/jdk1.8.0_101/lib/tools.jar:/home/hbase-1.2.2:/home/hbase-1.2.2/lib/activation-1.1.jar:/home/hbase-1.2.2/lib/antisamy-1.5.3.jar:/home/hbase-1.2.2/lib/aopalliance-1.0.jar:/home/hbase-1.2.2/lib/apacheds-i18n-2.0.0-M15.jar:/home/hbase-1.2.2/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hbase-1.2.2/lib/api-asn1-api-1.0.0-M20.jar:/home/hbase-1.2.2/lib/api-util-1.0.0-M20.jar:/home/hbase-1.2.2/lib/asm-3.1.jar:/home/hbase-1.2.2/lib/avro-1.7.4.jar:/home/hbase-1.2.2/lib/batik-css-1.8.jar:/home/hbase-1.2.2/lib/batik-ext-1.8.jar:/home/hbase-1.2.2/lib/batik-util-1.8.jar:/home/hbase-1.2.2/lib/bsh-core-2.0b4.jar:/home/hbase-1.2.2/lib/commons-beanutils-1.7.0.jar:/home/hbase-1.2.2/lib/commons-beanutils-core-1.8.3.jar:/home/hbase-1.2.2/lib/commons-cli-1.2.jar:/home/hbase-1.2.2/lib/commons-codec-1.9.jar:/home/hbase-1.2.2/lib/commons-collections-3.2.2.jar:/home/hbase-1.2.2/lib/commons-compress-1.4.1.jar:/home/hbase-1.2.2/lib/commons-configuration-1.6.jar:/home/hbase-1.2.2/lib/commons-daemon-1.0.13.jar:/home/hbase-1.2.2/lib/commons-digester-1.8.jar:/home/hbase-1.2.2/lib/commons-el-1.0.jar:/home/hbase-1.2.2/lib/commons-fileupload-1.3.1.jar:/home/hbase-1.2.2/lib/commons-httpclient-3.1.jar:/home/hbase-1.2.2/lib/commons-io-2.4.jar:/home/hbase-1.2.2/lib/commons-lang-2.6.jar:/home/hbase-1.2.2/lib/commons-logging-1.2.jar:/home/hbase-1.2.2/lib/commons-math-2.2.jar:/home/hbase-1.2.2/lib/commons-math3-3.1.1.jar:/home/hbase-1.2.2/lib/commons-net-3.1.jar:/home/hbase-1.2.2/lib/disruptor-3.3.0.jar:/home/hbase-1.2.2/lib/esapi-2.1.0.1.jar:/home/hbase-1.2.2/lib/findbugs-annotations-1.3.9-1.jar:/home/hbase-1.2.2/lib/guava-12.0.1.jar:/home/hbase-1.2.2/lib/guice-3.0.jar:/home/hbase-1.2.2/lib/guice-servlet-3.0.jar:/home/hbase-1.2.2/lib/hadoop-annotations-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-auth-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-hdfs-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-app-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-core-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-api-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-server-common-2.5.1.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-client-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-examples-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-external-blockcache-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop2-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-prefix-tree-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-procedure-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-protocol-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-resource-bundle-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-rest-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-shell-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-thrift-1.2.2.jar:/home/hbase-1.2.2/lib/htrace-core-3.1.0-incubating.jar:/home/hbase-1.2.2/lib/httpclient-4.2.5.jar:/home/hbase-1.2.2/lib/httpcore-4.4.1.jar:/home/hbase-1.2.2/lib/jackson-core-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-jaxrs-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-mapper-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-xc-1.9.13.jar:/home/hbase-1.2.2/lib/jamon-runtime-2.4.1.jar:/home/hbase-1.2.2/lib/jasper-compiler-5.5.23.jar:/home/hbase-1.2.2/lib/jasper-runtime-5.5.23.jar:/home/hbase-1.2.2/lib/javax.inject-1.jar:/home/hbase-1.2.2/lib/java-xmlbuilder-0.4.jar:/home/hbase-1.2.2/lib/jaxb-api-2.2.2.jar:/home/hbase-1.2.2/lib/jaxb-impl-2.2.3-1.jar:/home/hbase-1.2.2/lib/jcodings-1.0.8.jar:/home/hbase-1.2.2/lib/jersey-client-1.9.jar:/home/hbase-1.2.2/lib/jersey-core-1.9.jar:/home/hbase-1.2.2/lib/jersey-guice-1.9.jar:/home/hbase-1.2.2/lib/jersey-json-1.9.jar:/home/hbase-1.2.2/lib/jersey-server-1.9.jar:/home/hbase-1.2.2/lib/jets3t-0.9.0.jar:/home/hbase-1.2.2/lib/jettison-1.3.3.jar:/home/hbase-1.2.2/lib/jetty-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-sslengine-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-util-6.1.26.jar:/home/hbase-1.2.2/lib/joni-2.1.2.jar:/home/hbase-1.2.2/lib/jruby-complete-1.6.8.jar:/home/hbase-1.2.2/lib/jsch-0.1.42.jar:/home/hbase-1.2.2/lib/jsp-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsp-api-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsr305-1.3.9.jar:/home/hbase-1.2.2/lib/junit-4.12.jar:/home/hbase-1.2.2/lib/leveldbjni-all-1.8.jar:/home/hbase-1.2.2/lib/libthrift-0.9.3.jar:/home/hbase-1.2.2/lib/log4j-1.2.17.jar:/home/hbase-1.2.2/lib/metrics-core-2.2.0.jar:/home/hbase-1.2.2/lib/nekohtml-1.9.16.jar:/home/hbase-1.2.2/lib/netty-all-4.0.23.Final.jar:/home/hbase-1.2.2/lib/paranamer-2.3.jar:/home/hbase-1.2.2/lib/protobuf-java-2.5.0.jar:/home/hbase-1.2.2/lib/servlet-api-2.5-6.1.14.jar:/home/hbase-1.2.2/lib/servlet-api-2.5.jar:/home/hbase-1.2.2/lib/slf4j-api-1.7.7.jar:/home/hbase-1.2.2/lib/slf4j-log4j12-1.7.5.jar:/home/hbase-1.2.2/lib/snappy-java-1.0.4.1.jar:/home/hbase-1.2.2/lib/spymemcached-2.11.6.jar:/home/hbase-1.2.2/lib/xalan-2.7.0.jar:/home/hbase-1.2.2/lib/xml-apis-1.3.03.jar:/home/hbase-1.2.2/lib/xml-apis-ext-1.3.04.jar:/home/hbase-1.2.2/lib/xmlenc-0.52.jar:/home/hbase-1.2.2/lib/xom-1.2.5.jar:/home/hbase-1.2.2/lib/xz-1.0.jar:/home/hbase-1.2.2/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/etc/hadoop:/home/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/hpme/hadoop-2.7.3/share/hadoop/mapreduce/*:/home/hadoop-2.7.3/contrib/capacity-scheduler/*.jar
2019-05-04 17:27:00,471 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop-2.7.3/lib/native
2019-05-04 17:27:00,471 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2019-05-04 17:27:00,471 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2019-05-04 17:27:00,471 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2019-05-04 17:27:00,471 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=i386
2019-05-04 17:27:00,471 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=3.10.0-957.10.1.el7.x86_64
2019-05-04 17:27:00,471 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=root
2019-05-04 17:27:00,471 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/root
2019-05-04 17:27:00,471 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hbase-1.2.2
2019-05-04 17:27:00,474 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=master:160000x0, quorum=localhost:2181, baseZNode=/hbase
2019-05-04 17:27:00,487 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2019-05-04 17:27:00,490 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2019-05-04 17:27:00,514 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16a83749a010000, negotiated timeout = 90000
2019-05-04 17:27:00,556 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2019-05-04 17:27:00,557 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: starting
2019-05-04 17:27:00,628 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-05-04 17:27:00,646 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2019-05-04 17:27:00,655 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2019-05-04 17:27:00,655 INFO  [main] http.HttpServer: Added global filter 'clickjackingprevention' (class=org.apache.hadoop.hbase.http.ClickjackingPreventionFilter)
2019-05-04 17:27:00,661 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2019-05-04 17:27:00,661 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-05-04 17:27:00,661 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-05-04 17:27:00,675 INFO  [main] http.HttpServer: Jetty bound to port 16010
2019-05-04 17:27:00,675 INFO  [main] mortbay.log: jetty-6.1.26
2019-05-04 17:27:00,945 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2019-05-04 17:27:00,949 INFO  [main] master.HMaster: hbase.rootdir=hdfs://master:9000/hbase, hbase.cluster.distributed=true
2019-05-04 17:27:00,959 INFO  [main] master.HMaster: Adding backup master ZNode /hbase/backup-masters/master,16000,1556983619887
2019-05-04 17:27:01,038 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/master,16000,1556983619887 from backup master directory
2019-05-04 17:27:01,060 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Registered Active Master=master,16000,1556983619887
2019-05-04 17:27:01,090 INFO  [master/master/192.168.178.37:16000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x51bfba connecting to ZooKeeper ensemble=localhost:2181
2019-05-04 17:27:01,090 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x51bfba0x0, quorum=localhost:2181, baseZNode=/hbase
2019-05-04 17:27:01,111 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2019-05-04 17:27:01,111 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2019-05-04 17:27:01,130 FATAL [master:16000.activeMasterManager] master.HMaster: Failed to become active master
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setSafeMode(ClientNamenodeProtocolTranslatorPB.java:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.setSafeMode(DFSClient.java:2264)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:986)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:970)
	at org.apache.hadoop.hbase.util.FSUtils.isInSafeMode(FSUtils.java:525)
	at org.apache.hadoop.hbase.util.FSUtils.waitOnSafeMode(FSUtils.java:971)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:424)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:153)
	at org.apache.hadoop.hbase.master.MasterFileSystem.<init>(MasterFileSystem.java:128)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:652)
	at org.apache.hadoop.hbase.master.HMaster.access$600(HMaster.java:185)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1750)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 29 more
2019-05-04 17:27:01,131 FATAL [master:16000.activeMasterManager] master.HMaster: Unhandled exception. Starting shutdown.
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setSafeMode(ClientNamenodeProtocolTranslatorPB.java:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.setSafeMode(DFSClient.java:2264)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:986)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:970)
	at org.apache.hadoop.hbase.util.FSUtils.isInSafeMode(FSUtils.java:525)
	at org.apache.hadoop.hbase.util.FSUtils.waitOnSafeMode(FSUtils.java:971)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:424)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:153)
	at org.apache.hadoop.hbase.master.MasterFileSystem.<init>(MasterFileSystem.java:128)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:652)
	at org.apache.hadoop.hbase.master.HMaster.access$600(HMaster.java:185)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1750)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 29 more
2019-05-04 17:27:01,131 INFO  [master:16000.activeMasterManager] regionserver.HRegionServer: STOPPED: Unhandled exception. Starting shutdown.
2019-05-04 17:27:01,132 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16a83749a010001, negotiated timeout = 90000
2019-05-04 17:27:01,132 INFO  [master/master/192.168.178.37:16000] client.ZooKeeperRegistry: ClusterId read in ZooKeeper is null
2019-05-04 17:27:04,186 INFO  [master/master/192.168.178.37:16000] ipc.RpcServer: Stopping server on 16000
2019-05-04 17:27:04,186 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: stopping
2019-05-04 17:27:04,187 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: Stopping infoServer
2019-05-04 17:27:04,199 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2019-05-04 17:27:04,199 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2019-05-04 17:27:04,231 INFO  [master/master/192.168.178.37:16000] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:16010
2019-05-04 17:27:04,231 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1556983619887
2019-05-04 17:27:04,231 INFO  [master/master/192.168.178.37:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x16a83749a010001
2019-05-04 17:27:04,235 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Session: 0x16a83749a010001 closed
2019-05-04 17:27:04,238 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1556983619887; all regions closed.
2019-05-04 17:27:04,238 INFO  [master/master/192.168.178.37:16000-EventThread] zookeeper.ClientCnxn: EventThread shut down
2019-05-04 17:27:04,238 INFO  [master/master/192.168.178.37:16000] hbase.ChoreService: Chore service for: master,16000,1556983619887 had [] on shutdown
2019-05-04 17:27:04,244 INFO  [master/master/192.168.178.37:16000] ipc.RpcServer: Stopping server on 16000
2019-05-04 17:27:04,246 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Session: 0x16a83749a010000 closed
2019-05-04 17:27:04,246 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1556983619887; zookeeper connection closed.
2019-05-04 17:27:04,246 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: master/master/192.168.178.37:16000 exiting
2019-05-04 17:27:04,246 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
Sa 4. Mai 17:27:25 CEST 2019 Stopping hbase (via master)
Mo 13. Mai 18:37:56 CEST 2019 Starting master on master
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 14924
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 14924
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2019-05-13 18:37:56,831 INFO  [main] util.VersionInfo: HBase 1.2.2
2019-05-13 18:37:56,834 INFO  [main] util.VersionInfo: Source code repository git://asf-dev/home/busbey/projects/hbase revision=3f671c1ead70d249ea4598f1bbcc5151322b3a13
2019-05-13 18:37:56,834 INFO  [main] util.VersionInfo: Compiled by busbey on Fri Jul  1 08:28:55 CDT 2016
2019-05-13 18:37:56,834 INFO  [main] util.VersionInfo: From source with checksum 7ac43c3d2f62f134b2a6aa1a05ad66ac
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:PATH=/home/jdk1.8.0_101/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/home/hadoop-2.7.3:/home/hadoop-2.7.3/bin/:/home/hbase-1.2.2/bin:/root/bin
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF_DIR=/home/hadoop-2.7.3/etc/hadoop
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:XDG_DATA_DIRS=/root/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/root
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/home/hadoop-2.7.3/lib/native
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:LOGNAME=root
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:PWD=/home/hbase-1.2.2
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:SELINUX_USE_CURRENT_RANGE=
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/home/hadoop-2.7.3
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -XX:PermSize=128m -XX:MaxPermSize=128m -Dhbase.log.dir=/home/hbase-1.2.2/logs -Dhbase.log.file=hbase-root-master-master.log -Dhbase.home.dir=/home/hbase-1.2.2 -Dhbase.id.str=root -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop-2.7.3/lib/native -Dhbase.security.logger=INFO,RFAS
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase-root-master.autorestart
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.Z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38;5;9:*.rar=38;5;9:*.alz=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.cab=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.axv=38;5;13:*.anx=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2019-05-13 18:37:57,144 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-root-master-master.log
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/home/jdk1.8.0_101
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:TERM=xterm-256color
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:LANG=de_DE.UTF-8
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=2
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:SELINUX_LEVEL_REQUESTED=
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:SELINUX_ROLE_REQUESTED=
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:YARN_HOME=/home/hadoop-2.7.3
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:HADOOP_HDFS_HOME=/home/hadoop-2.7.3
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:HADOOP_MAPRED_HOME=/hpme/hadoop-2.7.3
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_HOME=/home/hadoop-2.7.3
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=root
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase-root-master.znode
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:SSH_TTY=/dev/pts/0
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=192.168.178.62 53639 22
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-root-master-master
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hbase-1.2.2/logs
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:USER=root
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hbase-1.2.2/conf:/home/jdk1.8.0_101/lib/tools.jar:/home/hbase-1.2.2:/home/hbase-1.2.2/lib/activation-1.1.jar:/home/hbase-1.2.2/lib/antisamy-1.5.3.jar:/home/hbase-1.2.2/lib/aopalliance-1.0.jar:/home/hbase-1.2.2/lib/apacheds-i18n-2.0.0-M15.jar:/home/hbase-1.2.2/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hbase-1.2.2/lib/api-asn1-api-1.0.0-M20.jar:/home/hbase-1.2.2/lib/api-util-1.0.0-M20.jar:/home/hbase-1.2.2/lib/asm-3.1.jar:/home/hbase-1.2.2/lib/avro-1.7.4.jar:/home/hbase-1.2.2/lib/batik-css-1.8.jar:/home/hbase-1.2.2/lib/batik-ext-1.8.jar:/home/hbase-1.2.2/lib/batik-util-1.8.jar:/home/hbase-1.2.2/lib/bsh-core-2.0b4.jar:/home/hbase-1.2.2/lib/commons-beanutils-1.7.0.jar:/home/hbase-1.2.2/lib/commons-beanutils-core-1.8.3.jar:/home/hbase-1.2.2/lib/commons-cli-1.2.jar:/home/hbase-1.2.2/lib/commons-codec-1.9.jar:/home/hbase-1.2.2/lib/commons-collections-3.2.2.jar:/home/hbase-1.2.2/lib/commons-compress-1.4.1.jar:/home/hbase-1.2.2/lib/commons-configuration-1.6.jar:/home/hbase-1.2.2/lib/commons-daemon-1.0.13.jar:/home/hbase-1.2.2/lib/commons-digester-1.8.jar:/home/hbase-1.2.2/lib/commons-el-1.0.jar:/home/hbase-1.2.2/lib/commons-fileupload-1.3.1.jar:/home/hbase-1.2.2/lib/commons-httpclient-3.1.jar:/home/hbase-1.2.2/lib/commons-io-2.4.jar:/home/hbase-1.2.2/lib/commons-lang-2.6.jar:/home/hbase-1.2.2/lib/commons-logging-1.2.jar:/home/hbase-1.2.2/lib/commons-math-2.2.jar:/home/hbase-1.2.2/lib/commons-math3-3.1.1.jar:/home/hbase-1.2.2/lib/commons-net-3.1.jar:/home/hbase-1.2.2/lib/disruptor-3.3.0.jar:/home/hbase-1.2.2/lib/esapi-2.1.0.1.jar:/home/hbase-1.2.2/lib/findbugs-annotations-1.3.9-1.jar:/home/hbase-1.2.2/lib/guava-12.0.1.jar:/home/hbase-1.2.2/lib/guice-3.0.jar:/home/hbase-1.2.2/lib/guice-servlet-3.0.jar:/home/hbase-1.2.2/lib/hadoop-annotations-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-auth-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-hdfs-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-app-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-core-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-api-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-server-common-2.5.1.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-client-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-examples-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-external-blockcache-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop2-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-prefix-tree-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-procedure-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-protocol-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-resource-bundle-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-rest-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-shell-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-thrift-1.2.2.jar:/home/hbase-1.2.2/lib/htrace-core-3.1.0-incubating.jar:/home/hbase-1.2.2/lib/httpclient-4.2.5.jar:/home/hbase-1.2.2/lib/httpcore-4.4.1.jar:/home/hbase-1.2.2/lib/jackson-core-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-jaxrs-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-mapper-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-xc-1.9.13.jar:/home/hbase-1.2.2/lib/jamon-runtime-2.4.1.jar:/home/hbase-1.2.2/lib/jasper-compiler-5.5.23.jar:/home/hbase-1.2.2/lib/jasper-runtime-5.5.23.jar:/home/hbase-1.2.2/lib/javax.inject-1.jar:/home/hbase-1.2.2/lib/java-xmlbuilder-0.4.jar:/home/hbase-1.2.2/lib/jaxb-api-2.2.2.jar:/home/hbase-1.2.2/lib/jaxb-impl-2.2.3-1.jar:/home/hbase-1.2.2/lib/jcodings-1.0.8.jar:/home/hbase-1.2.2/lib/jersey-client-1.9.jar:/home/hbase-1.2.2/lib/jersey-core-1.9.jar:/home/hbase-1.2.2/lib/jersey-guice-1.9.jar:/home/hbase-1.2.2/lib/jersey-json-1.9.jar:/home/hbase-1.2.2/lib/jersey-server-1.9.jar:/home/hbase-1.2.2/lib/jets3t-0.9.0.jar:/home/hbase-1.2.2/lib/jettison-1.3.3.jar:/home/hbase-1.2.2/lib/jetty-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-sslengine-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-util-6.1.26.jar:/home/hbase-1.2.2/lib/joni-2.1.2.jar:/home/hbase-1.2.2/lib/jruby-complete-1.6.8.jar:/home/hbase-1.2.2/lib/jsch-0.1.42.jar:/home/hbase-1.2.2/lib/jsp-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsp-api-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsr305-1.3.9.jar:/home/hbase-1.2.2/lib/junit-4.12.jar:/home/hbase-1.2.2/lib/leveldbjni-all-1.8.jar:/home/hbase-1.2.2/lib/libthrift-0.9.3.jar:/home/hbase-1.2.2/lib/log4j-1.2.17.jar:/home/hbase-1.2.2/lib/metrics-core-2.2.0.jar:/home/hbase-1.2.2/lib/nekohtml-1.9.16.jar:/home/hbase-1.2.2/lib/netty-all-4.0.23.Final.jar:/home/hbase-1.2.2/lib/paranamer-2.3.jar:/home/hbase-1.2.2/lib/protobuf-java-2.5.0.jar:/home/hbase-1.2.2/lib/servlet-api-2.5-6.1.14.jar:/home/hbase-1.2.2/lib/servlet-api-2.5.jar:/home/hbase-1.2.2/lib/slf4j-api-1.7.7.jar:/home/hbase-1.2.2/lib/slf4j-log4j12-1.7.5.jar:/home/hbase-1.2.2/lib/snappy-java-1.0.4.1.jar:/home/hbase-1.2.2/lib/spymemcached-2.11.6.jar:/home/hbase-1.2.2/lib/xalan-2.7.0.jar:/home/hbase-1.2.2/lib/xml-apis-1.3.03.jar:/home/hbase-1.2.2/lib/xml-apis-ext-1.3.04.jar:/home/hbase-1.2.2/lib/xmlenc-0.52.jar:/home/hbase-1.2.2/lib/xom-1.2.5.jar:/home/hbase-1.2.2/lib/xz-1.0.jar:/home/hbase-1.2.2/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/etc/hadoop:/home/hadoop-2.7.3/share/hadoop/common/lib/*:/home/hadoop-2.7.3/share/hadoop/common/*:/home/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/*:/home/hadoop-2.7.3/share/hadoop/hdfs/*:/home/hadoop-2.7.3/share/hadoop/yarn/lib/*:/home/hadoop-2.7.3/share/hadoop/yarn/*:/hpme/hadoop-2.7.3/share/hadoop/mapreduce/*:/home/hadoop-2.7.3/contrib/capacity-scheduler/*.jar
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=192.168.178.62 53639 192.168.178.37 22
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:HOSTNAME=master
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/0
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hbase-1.2.2
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:HOME=/root
2019-05-13 18:37:57,145 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2019-05-13 18:37:57,146 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) Client VM, vmVendor=Oracle Corporation, vmVersion=25.101-b13
2019-05-13 18:37:57,147 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -XX:+UseConcMarkSweepGC, -XX:PermSize=128m, -XX:MaxPermSize=128m, -Dhbase.log.dir=/home/hbase-1.2.2/logs, -Dhbase.log.file=hbase-root-master-master.log, -Dhbase.home.dir=/home/hbase-1.2.2, -Dhbase.id.str=root, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop-2.7.3/lib/native, -Dhbase.security.logger=INFO,RFAS]
2019-05-13 18:37:57,299 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-05-13 18:37:57,538 INFO  [main] regionserver.RSRpcServices: master/master/192.168.178.37:16000 server-side HConnection retries=350
2019-05-13 18:37:57,692 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2019-05-13 18:37:57,714 INFO  [main] ipc.RpcServer: master/master/192.168.178.37:16000: started 10 reader(s) listening on port=16000
2019-05-13 18:37:57,803 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2019-05-13 18:37:57,877 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-05-13 18:37:57,877 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2019-05-13 18:37:58,451 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2019-05-13 18:37:58,613 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16000 connecting to ZooKeeper ensemble=localhost:2181
2019-05-13 18:37:58,622 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2019-05-13 18:37:58,622 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=master
2019-05-13 18:37:58,622 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_101
2019-05-13 18:37:58,622 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2019-05-13 18:37:58,622 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/home/jdk1.8.0_101/jre
2019-05-13 18:37:58,622 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hbase-1.2.2/conf:/home/jdk1.8.0_101/lib/tools.jar:/home/hbase-1.2.2:/home/hbase-1.2.2/lib/activation-1.1.jar:/home/hbase-1.2.2/lib/antisamy-1.5.3.jar:/home/hbase-1.2.2/lib/aopalliance-1.0.jar:/home/hbase-1.2.2/lib/apacheds-i18n-2.0.0-M15.jar:/home/hbase-1.2.2/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hbase-1.2.2/lib/api-asn1-api-1.0.0-M20.jar:/home/hbase-1.2.2/lib/api-util-1.0.0-M20.jar:/home/hbase-1.2.2/lib/asm-3.1.jar:/home/hbase-1.2.2/lib/avro-1.7.4.jar:/home/hbase-1.2.2/lib/batik-css-1.8.jar:/home/hbase-1.2.2/lib/batik-ext-1.8.jar:/home/hbase-1.2.2/lib/batik-util-1.8.jar:/home/hbase-1.2.2/lib/bsh-core-2.0b4.jar:/home/hbase-1.2.2/lib/commons-beanutils-1.7.0.jar:/home/hbase-1.2.2/lib/commons-beanutils-core-1.8.3.jar:/home/hbase-1.2.2/lib/commons-cli-1.2.jar:/home/hbase-1.2.2/lib/commons-codec-1.9.jar:/home/hbase-1.2.2/lib/commons-collections-3.2.2.jar:/home/hbase-1.2.2/lib/commons-compress-1.4.1.jar:/home/hbase-1.2.2/lib/commons-configuration-1.6.jar:/home/hbase-1.2.2/lib/commons-daemon-1.0.13.jar:/home/hbase-1.2.2/lib/commons-digester-1.8.jar:/home/hbase-1.2.2/lib/commons-el-1.0.jar:/home/hbase-1.2.2/lib/commons-fileupload-1.3.1.jar:/home/hbase-1.2.2/lib/commons-httpclient-3.1.jar:/home/hbase-1.2.2/lib/commons-io-2.4.jar:/home/hbase-1.2.2/lib/commons-lang-2.6.jar:/home/hbase-1.2.2/lib/commons-logging-1.2.jar:/home/hbase-1.2.2/lib/commons-math-2.2.jar:/home/hbase-1.2.2/lib/commons-math3-3.1.1.jar:/home/hbase-1.2.2/lib/commons-net-3.1.jar:/home/hbase-1.2.2/lib/disruptor-3.3.0.jar:/home/hbase-1.2.2/lib/esapi-2.1.0.1.jar:/home/hbase-1.2.2/lib/findbugs-annotations-1.3.9-1.jar:/home/hbase-1.2.2/lib/guava-12.0.1.jar:/home/hbase-1.2.2/lib/guice-3.0.jar:/home/hbase-1.2.2/lib/guice-servlet-3.0.jar:/home/hbase-1.2.2/lib/hadoop-annotations-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-auth-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-hdfs-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-app-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-core-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-api-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-server-common-2.5.1.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-client-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-examples-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-external-blockcache-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop2-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-prefix-tree-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-procedure-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-protocol-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-resource-bundle-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-rest-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-shell-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-thrift-1.2.2.jar:/home/hbase-1.2.2/lib/htrace-core-3.1.0-incubating.jar:/home/hbase-1.2.2/lib/httpclient-4.2.5.jar:/home/hbase-1.2.2/lib/httpcore-4.4.1.jar:/home/hbase-1.2.2/lib/jackson-core-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-jaxrs-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-mapper-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-xc-1.9.13.jar:/home/hbase-1.2.2/lib/jamon-runtime-2.4.1.jar:/home/hbase-1.2.2/lib/jasper-compiler-5.5.23.jar:/home/hbase-1.2.2/lib/jasper-runtime-5.5.23.jar:/home/hbase-1.2.2/lib/javax.inject-1.jar:/home/hbase-1.2.2/lib/java-xmlbuilder-0.4.jar:/home/hbase-1.2.2/lib/jaxb-api-2.2.2.jar:/home/hbase-1.2.2/lib/jaxb-impl-2.2.3-1.jar:/home/hbase-1.2.2/lib/jcodings-1.0.8.jar:/home/hbase-1.2.2/lib/jersey-client-1.9.jar:/home/hbase-1.2.2/lib/jersey-core-1.9.jar:/home/hbase-1.2.2/lib/jersey-guice-1.9.jar:/home/hbase-1.2.2/lib/jersey-json-1.9.jar:/home/hbase-1.2.2/lib/jersey-server-1.9.jar:/home/hbase-1.2.2/lib/jets3t-0.9.0.jar:/home/hbase-1.2.2/lib/jettison-1.3.3.jar:/home/hbase-1.2.2/lib/jetty-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-sslengine-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-util-6.1.26.jar:/home/hbase-1.2.2/lib/joni-2.1.2.jar:/home/hbase-1.2.2/lib/jruby-complete-1.6.8.jar:/home/hbase-1.2.2/lib/jsch-0.1.42.jar:/home/hbase-1.2.2/lib/jsp-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsp-api-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsr305-1.3.9.jar:/home/hbase-1.2.2/lib/junit-4.12.jar:/home/hbase-1.2.2/lib/leveldbjni-all-1.8.jar:/home/hbase-1.2.2/lib/libthrift-0.9.3.jar:/home/hbase-1.2.2/lib/log4j-1.2.17.jar:/home/hbase-1.2.2/lib/metrics-core-2.2.0.jar:/home/hbase-1.2.2/lib/nekohtml-1.9.16.jar:/home/hbase-1.2.2/lib/netty-all-4.0.23.Final.jar:/home/hbase-1.2.2/lib/paranamer-2.3.jar:/home/hbase-1.2.2/lib/protobuf-java-2.5.0.jar:/home/hbase-1.2.2/lib/servlet-api-2.5-6.1.14.jar:/home/hbase-1.2.2/lib/servlet-api-2.5.jar:/home/hbase-1.2.2/lib/slf4j-api-1.7.7.jar:/home/hbase-1.2.2/lib/slf4j-log4j12-1.7.5.jar:/home/hbase-1.2.2/lib/snappy-java-1.0.4.1.jar:/home/hbase-1.2.2/lib/spymemcached-2.11.6.jar:/home/hbase-1.2.2/lib/xalan-2.7.0.jar:/home/hbase-1.2.2/lib/xml-apis-1.3.03.jar:/home/hbase-1.2.2/lib/xml-apis-ext-1.3.04.jar:/home/hbase-1.2.2/lib/xmlenc-0.52.jar:/home/hbase-1.2.2/lib/xom-1.2.5.jar:/home/hbase-1.2.2/lib/xz-1.0.jar:/home/hbase-1.2.2/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/etc/hadoop:/home/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/hpme/hadoop-2.7.3/share/hadoop/mapreduce/*:/home/hadoop-2.7.3/contrib/capacity-scheduler/*.jar
2019-05-13 18:37:58,623 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop-2.7.3/lib/native
2019-05-13 18:37:58,623 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2019-05-13 18:37:58,623 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2019-05-13 18:37:58,623 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2019-05-13 18:37:58,623 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=i386
2019-05-13 18:37:58,623 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=3.10.0-957.12.1.el7.x86_64
2019-05-13 18:37:58,623 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=root
2019-05-13 18:37:58,623 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/root
2019-05-13 18:37:58,623 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hbase-1.2.2
2019-05-13 18:37:58,626 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=master:160000x0, quorum=localhost:2181, baseZNode=/hbase
2019-05-13 18:37:58,658 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2019-05-13 18:37:58,662 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2019-05-13 18:37:58,711 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16ab20ecf1a0000, negotiated timeout = 90000
2019-05-13 18:37:58,765 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2019-05-13 18:37:58,766 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: starting
2019-05-13 18:37:58,933 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-05-13 18:37:58,937 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2019-05-13 18:37:58,951 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2019-05-13 18:37:58,952 INFO  [main] http.HttpServer: Added global filter 'clickjackingprevention' (class=org.apache.hadoop.hbase.http.ClickjackingPreventionFilter)
2019-05-13 18:37:58,953 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2019-05-13 18:37:58,953 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-05-13 18:37:58,953 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-05-13 18:37:58,979 INFO  [main] http.HttpServer: Jetty bound to port 16010
2019-05-13 18:37:58,979 INFO  [main] mortbay.log: jetty-6.1.26
2019-05-13 18:37:59,486 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2019-05-13 18:37:59,496 INFO  [main] master.HMaster: hbase.rootdir=hdfs://master:9000/hbase, hbase.cluster.distributed=true
2019-05-13 18:37:59,518 INFO  [main] master.HMaster: Adding backup master ZNode /hbase/backup-masters/master,16000,1557765477893
2019-05-13 18:37:59,679 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/master,16000,1557765477893 from backup master directory
2019-05-13 18:37:59,698 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Registered Active Master=master,16000,1557765477893
2019-05-13 18:37:59,787 INFO  [master/master/192.168.178.37:16000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x18b13f4 connecting to ZooKeeper ensemble=localhost:2181
2019-05-13 18:37:59,787 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x18b13f40x0, quorum=localhost:2181, baseZNode=/hbase
2019-05-13 18:37:59,819 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2019-05-13 18:37:59,819 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2019-05-13 18:37:59,833 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16ab20ecf1a0001, negotiated timeout = 90000
2019-05-13 18:37:59,834 INFO  [master/master/192.168.178.37:16000] client.ZooKeeperRegistry: ClusterId read in ZooKeeper is null
2019-05-13 18:37:59,864 FATAL [master:16000.activeMasterManager] master.HMaster: Failed to become active master
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setSafeMode(ClientNamenodeProtocolTranslatorPB.java:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.setSafeMode(DFSClient.java:2264)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:986)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:970)
	at org.apache.hadoop.hbase.util.FSUtils.isInSafeMode(FSUtils.java:525)
	at org.apache.hadoop.hbase.util.FSUtils.waitOnSafeMode(FSUtils.java:971)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:424)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:153)
	at org.apache.hadoop.hbase.master.MasterFileSystem.<init>(MasterFileSystem.java:128)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:652)
	at org.apache.hadoop.hbase.master.HMaster.access$600(HMaster.java:185)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1750)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 29 more
2019-05-13 18:37:59,889 FATAL [master:16000.activeMasterManager] master.HMaster: Unhandled exception. Starting shutdown.
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setSafeMode(ClientNamenodeProtocolTranslatorPB.java:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.setSafeMode(DFSClient.java:2264)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:986)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:970)
	at org.apache.hadoop.hbase.util.FSUtils.isInSafeMode(FSUtils.java:525)
	at org.apache.hadoop.hbase.util.FSUtils.waitOnSafeMode(FSUtils.java:971)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:424)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:153)
	at org.apache.hadoop.hbase.master.MasterFileSystem.<init>(MasterFileSystem.java:128)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:652)
	at org.apache.hadoop.hbase.master.HMaster.access$600(HMaster.java:185)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1750)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 29 more
2019-05-13 18:37:59,890 INFO  [master:16000.activeMasterManager] regionserver.HRegionServer: STOPPED: Unhandled exception. Starting shutdown.
2019-05-13 18:38:02,932 INFO  [master/master/192.168.178.37:16000] ipc.RpcServer: Stopping server on 16000
2019-05-13 18:38:02,932 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: stopping
2019-05-13 18:38:02,932 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: Stopping infoServer
2019-05-13 18:38:02,944 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2019-05-13 18:38:02,944 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2019-05-13 18:38:02,973 INFO  [master/master/192.168.178.37:16000] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:16010
2019-05-13 18:38:02,974 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1557765477893
2019-05-13 18:38:02,974 INFO  [master/master/192.168.178.37:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x16ab20ecf1a0001
2019-05-13 18:38:02,978 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Session: 0x16ab20ecf1a0001 closed
2019-05-13 18:38:02,979 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1557765477893; all regions closed.
2019-05-13 18:38:02,979 INFO  [master/master/192.168.178.37:16000-EventThread] zookeeper.ClientCnxn: EventThread shut down
2019-05-13 18:38:02,980 INFO  [master/master/192.168.178.37:16000] hbase.ChoreService: Chore service for: master,16000,1557765477893 had [] on shutdown
2019-05-13 18:38:02,988 INFO  [master/master/192.168.178.37:16000] ipc.RpcServer: Stopping server on 16000
2019-05-13 18:38:02,990 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Session: 0x16ab20ecf1a0000 closed
2019-05-13 18:38:02,990 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1557765477893; zookeeper connection closed.
2019-05-13 18:38:02,991 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: master/master/192.168.178.37:16000 exiting
2019-05-13 18:38:02,991 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
Mo 13. Mai 18:39:17 CEST 2019 Stopping hbase (via master)
Mo 13. Mai 18:42:06 CEST 2019 Starting master on master
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 14923
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 14923
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2019-05-13 18:42:07,227 INFO  [main] util.VersionInfo: HBase 1.2.2
2019-05-13 18:42:07,228 INFO  [main] util.VersionInfo: Source code repository git://asf-dev/home/busbey/projects/hbase revision=3f671c1ead70d249ea4598f1bbcc5151322b3a13
2019-05-13 18:42:07,228 INFO  [main] util.VersionInfo: Compiled by busbey on Fri Jul  1 08:28:55 CDT 2016
2019-05-13 18:42:07,228 INFO  [main] util.VersionInfo: From source with checksum 7ac43c3d2f62f134b2a6aa1a05ad66ac
2019-05-13 18:42:07,533 INFO  [main] util.ServerCommandLine: env:PATH=/home/jdk1.8.0_101/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/home/hadoop-2.7.3:/home/hadoop-2.7.3/bin/:/home/hbase-1.2.2/bin:/root/bin
2019-05-13 18:42:07,533 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF_DIR=/home/hadoop-2.7.3/etc/hadoop
2019-05-13 18:42:07,533 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2019-05-13 18:42:07,533 INFO  [main] util.ServerCommandLine: env:XDG_DATA_DIRS=/root/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share
2019-05-13 18:42:07,533 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2019-05-13 18:42:07,533 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/root
2019-05-13 18:42:07,533 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/home/hadoop-2.7.3/lib/native
2019-05-13 18:42:07,533 INFO  [main] util.ServerCommandLine: env:LOGNAME=root
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:PWD=/home/hbase-1.2.2
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:SELINUX_USE_CURRENT_RANGE=
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/home/hadoop-2.7.3
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -XX:PermSize=128m -XX:MaxPermSize=128m -Dhbase.log.dir=/home/hbase-1.2.2/logs -Dhbase.log.file=hbase-root-master-master.log -Dhbase.home.dir=/home/hbase-1.2.2 -Dhbase.id.str=root -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop-2.7.3/lib/native -Dhbase.security.logger=INFO,RFAS
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase-root-master.autorestart
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.Z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38;5;9:*.rar=38;5;9:*.alz=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.cab=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.axv=38;5;13:*.anx=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-root-master-master.log
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/home/jdk1.8.0_101
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:TERM=xterm-256color
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:LANG=de_DE.UTF-8
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=2
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:SELINUX_LEVEL_REQUESTED=
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:SELINUX_ROLE_REQUESTED=
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:YARN_HOME=/home/hadoop-2.7.3
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HADOOP_HDFS_HOME=/home/hadoop-2.7.3
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HADOOP_MAPRED_HOME=/hpme/hadoop-2.7.3
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_HOME=/home/hadoop-2.7.3
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=root
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase-root-master.znode
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:SSH_TTY=/dev/pts/0
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=192.168.178.62 53746 22
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-root-master-master
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hbase-1.2.2/logs
2019-05-13 18:42:07,534 INFO  [main] util.ServerCommandLine: env:USER=root
2019-05-13 18:42:07,535 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hbase-1.2.2/conf:/home/jdk1.8.0_101/lib/tools.jar:/home/hbase-1.2.2:/home/hbase-1.2.2/lib/activation-1.1.jar:/home/hbase-1.2.2/lib/antisamy-1.5.3.jar:/home/hbase-1.2.2/lib/aopalliance-1.0.jar:/home/hbase-1.2.2/lib/apacheds-i18n-2.0.0-M15.jar:/home/hbase-1.2.2/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hbase-1.2.2/lib/api-asn1-api-1.0.0-M20.jar:/home/hbase-1.2.2/lib/api-util-1.0.0-M20.jar:/home/hbase-1.2.2/lib/asm-3.1.jar:/home/hbase-1.2.2/lib/avro-1.7.4.jar:/home/hbase-1.2.2/lib/batik-css-1.8.jar:/home/hbase-1.2.2/lib/batik-ext-1.8.jar:/home/hbase-1.2.2/lib/batik-util-1.8.jar:/home/hbase-1.2.2/lib/bsh-core-2.0b4.jar:/home/hbase-1.2.2/lib/commons-beanutils-1.7.0.jar:/home/hbase-1.2.2/lib/commons-beanutils-core-1.8.3.jar:/home/hbase-1.2.2/lib/commons-cli-1.2.jar:/home/hbase-1.2.2/lib/commons-codec-1.9.jar:/home/hbase-1.2.2/lib/commons-collections-3.2.2.jar:/home/hbase-1.2.2/lib/commons-compress-1.4.1.jar:/home/hbase-1.2.2/lib/commons-configuration-1.6.jar:/home/hbase-1.2.2/lib/commons-daemon-1.0.13.jar:/home/hbase-1.2.2/lib/commons-digester-1.8.jar:/home/hbase-1.2.2/lib/commons-el-1.0.jar:/home/hbase-1.2.2/lib/commons-fileupload-1.3.1.jar:/home/hbase-1.2.2/lib/commons-httpclient-3.1.jar:/home/hbase-1.2.2/lib/commons-io-2.4.jar:/home/hbase-1.2.2/lib/commons-lang-2.6.jar:/home/hbase-1.2.2/lib/commons-logging-1.2.jar:/home/hbase-1.2.2/lib/commons-math-2.2.jar:/home/hbase-1.2.2/lib/commons-math3-3.1.1.jar:/home/hbase-1.2.2/lib/commons-net-3.1.jar:/home/hbase-1.2.2/lib/disruptor-3.3.0.jar:/home/hbase-1.2.2/lib/esapi-2.1.0.1.jar:/home/hbase-1.2.2/lib/findbugs-annotations-1.3.9-1.jar:/home/hbase-1.2.2/lib/guava-12.0.1.jar:/home/hbase-1.2.2/lib/guice-3.0.jar:/home/hbase-1.2.2/lib/guice-servlet-3.0.jar:/home/hbase-1.2.2/lib/hadoop-annotations-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-auth-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-hdfs-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-app-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-core-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-api-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-server-common-2.5.1.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-client-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-examples-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-external-blockcache-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop2-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-prefix-tree-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-procedure-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-protocol-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-resource-bundle-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-rest-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-shell-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-thrift-1.2.2.jar:/home/hbase-1.2.2/lib/htrace-core-3.1.0-incubating.jar:/home/hbase-1.2.2/lib/httpclient-4.2.5.jar:/home/hbase-1.2.2/lib/httpcore-4.4.1.jar:/home/hbase-1.2.2/lib/jackson-core-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-jaxrs-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-mapper-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-xc-1.9.13.jar:/home/hbase-1.2.2/lib/jamon-runtime-2.4.1.jar:/home/hbase-1.2.2/lib/jasper-compiler-5.5.23.jar:/home/hbase-1.2.2/lib/jasper-runtime-5.5.23.jar:/home/hbase-1.2.2/lib/javax.inject-1.jar:/home/hbase-1.2.2/lib/java-xmlbuilder-0.4.jar:/home/hbase-1.2.2/lib/jaxb-api-2.2.2.jar:/home/hbase-1.2.2/lib/jaxb-impl-2.2.3-1.jar:/home/hbase-1.2.2/lib/jcodings-1.0.8.jar:/home/hbase-1.2.2/lib/jersey-client-1.9.jar:/home/hbase-1.2.2/lib/jersey-core-1.9.jar:/home/hbase-1.2.2/lib/jersey-guice-1.9.jar:/home/hbase-1.2.2/lib/jersey-json-1.9.jar:/home/hbase-1.2.2/lib/jersey-server-1.9.jar:/home/hbase-1.2.2/lib/jets3t-0.9.0.jar:/home/hbase-1.2.2/lib/jettison-1.3.3.jar:/home/hbase-1.2.2/lib/jetty-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-sslengine-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-util-6.1.26.jar:/home/hbase-1.2.2/lib/joni-2.1.2.jar:/home/hbase-1.2.2/lib/jruby-complete-1.6.8.jar:/home/hbase-1.2.2/lib/jsch-0.1.42.jar:/home/hbase-1.2.2/lib/jsp-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsp-api-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsr305-1.3.9.jar:/home/hbase-1.2.2/lib/junit-4.12.jar:/home/hbase-1.2.2/lib/leveldbjni-all-1.8.jar:/home/hbase-1.2.2/lib/libthrift-0.9.3.jar:/home/hbase-1.2.2/lib/log4j-1.2.17.jar:/home/hbase-1.2.2/lib/metrics-core-2.2.0.jar:/home/hbase-1.2.2/lib/nekohtml-1.9.16.jar:/home/hbase-1.2.2/lib/netty-all-4.0.23.Final.jar:/home/hbase-1.2.2/lib/paranamer-2.3.jar:/home/hbase-1.2.2/lib/protobuf-java-2.5.0.jar:/home/hbase-1.2.2/lib/servlet-api-2.5-6.1.14.jar:/home/hbase-1.2.2/lib/servlet-api-2.5.jar:/home/hbase-1.2.2/lib/slf4j-api-1.7.7.jar:/home/hbase-1.2.2/lib/slf4j-log4j12-1.7.5.jar:/home/hbase-1.2.2/lib/snappy-java-1.0.4.1.jar:/home/hbase-1.2.2/lib/spymemcached-2.11.6.jar:/home/hbase-1.2.2/lib/xalan-2.7.0.jar:/home/hbase-1.2.2/lib/xml-apis-1.3.03.jar:/home/hbase-1.2.2/lib/xml-apis-ext-1.3.04.jar:/home/hbase-1.2.2/lib/xmlenc-0.52.jar:/home/hbase-1.2.2/lib/xom-1.2.5.jar:/home/hbase-1.2.2/lib/xz-1.0.jar:/home/hbase-1.2.2/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/etc/hadoop:/home/hadoop-2.7.3/share/hadoop/common/lib/*:/home/hadoop-2.7.3/share/hadoop/common/*:/home/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/*:/home/hadoop-2.7.3/share/hadoop/hdfs/*:/home/hadoop-2.7.3/share/hadoop/yarn/lib/*:/home/hadoop-2.7.3/share/hadoop/yarn/*:/hpme/hadoop-2.7.3/share/hadoop/mapreduce/*:/home/hadoop-2.7.3/contrib/capacity-scheduler/*.jar
2019-05-13 18:42:07,535 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=192.168.178.62 53746 192.168.178.37 22
2019-05-13 18:42:07,535 INFO  [main] util.ServerCommandLine: env:HOSTNAME=master
2019-05-13 18:42:07,535 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2019-05-13 18:42:07,535 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/0
2019-05-13 18:42:07,535 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2019-05-13 18:42:07,535 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hbase-1.2.2
2019-05-13 18:42:07,535 INFO  [main] util.ServerCommandLine: env:HOME=/root
2019-05-13 18:42:07,535 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2019-05-13 18:42:07,536 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) Client VM, vmVendor=Oracle Corporation, vmVersion=25.101-b13
2019-05-13 18:42:07,536 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -XX:+UseConcMarkSweepGC, -XX:PermSize=128m, -XX:MaxPermSize=128m, -Dhbase.log.dir=/home/hbase-1.2.2/logs, -Dhbase.log.file=hbase-root-master-master.log, -Dhbase.home.dir=/home/hbase-1.2.2, -Dhbase.id.str=root, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop-2.7.3/lib/native, -Dhbase.security.logger=INFO,RFAS]
2019-05-13 18:42:07,685 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-05-13 18:42:07,919 INFO  [main] regionserver.RSRpcServices: master/master/192.168.178.37:16000 server-side HConnection retries=350
2019-05-13 18:42:08,077 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2019-05-13 18:42:08,099 INFO  [main] ipc.RpcServer: master/master/192.168.178.37:16000: started 10 reader(s) listening on port=16000
2019-05-13 18:42:08,189 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2019-05-13 18:42:08,265 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-05-13 18:42:08,265 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2019-05-13 18:42:08,840 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2019-05-13 18:42:09,008 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16000 connecting to ZooKeeper ensemble=localhost:2181
2019-05-13 18:42:09,036 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2019-05-13 18:42:09,036 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=master
2019-05-13 18:42:09,036 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_101
2019-05-13 18:42:09,036 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2019-05-13 18:42:09,036 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/home/jdk1.8.0_101/jre
2019-05-13 18:42:09,036 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hbase-1.2.2/conf:/home/jdk1.8.0_101/lib/tools.jar:/home/hbase-1.2.2:/home/hbase-1.2.2/lib/activation-1.1.jar:/home/hbase-1.2.2/lib/antisamy-1.5.3.jar:/home/hbase-1.2.2/lib/aopalliance-1.0.jar:/home/hbase-1.2.2/lib/apacheds-i18n-2.0.0-M15.jar:/home/hbase-1.2.2/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hbase-1.2.2/lib/api-asn1-api-1.0.0-M20.jar:/home/hbase-1.2.2/lib/api-util-1.0.0-M20.jar:/home/hbase-1.2.2/lib/asm-3.1.jar:/home/hbase-1.2.2/lib/avro-1.7.4.jar:/home/hbase-1.2.2/lib/batik-css-1.8.jar:/home/hbase-1.2.2/lib/batik-ext-1.8.jar:/home/hbase-1.2.2/lib/batik-util-1.8.jar:/home/hbase-1.2.2/lib/bsh-core-2.0b4.jar:/home/hbase-1.2.2/lib/commons-beanutils-1.7.0.jar:/home/hbase-1.2.2/lib/commons-beanutils-core-1.8.3.jar:/home/hbase-1.2.2/lib/commons-cli-1.2.jar:/home/hbase-1.2.2/lib/commons-codec-1.9.jar:/home/hbase-1.2.2/lib/commons-collections-3.2.2.jar:/home/hbase-1.2.2/lib/commons-compress-1.4.1.jar:/home/hbase-1.2.2/lib/commons-configuration-1.6.jar:/home/hbase-1.2.2/lib/commons-daemon-1.0.13.jar:/home/hbase-1.2.2/lib/commons-digester-1.8.jar:/home/hbase-1.2.2/lib/commons-el-1.0.jar:/home/hbase-1.2.2/lib/commons-fileupload-1.3.1.jar:/home/hbase-1.2.2/lib/commons-httpclient-3.1.jar:/home/hbase-1.2.2/lib/commons-io-2.4.jar:/home/hbase-1.2.2/lib/commons-lang-2.6.jar:/home/hbase-1.2.2/lib/commons-logging-1.2.jar:/home/hbase-1.2.2/lib/commons-math-2.2.jar:/home/hbase-1.2.2/lib/commons-math3-3.1.1.jar:/home/hbase-1.2.2/lib/commons-net-3.1.jar:/home/hbase-1.2.2/lib/disruptor-3.3.0.jar:/home/hbase-1.2.2/lib/esapi-2.1.0.1.jar:/home/hbase-1.2.2/lib/findbugs-annotations-1.3.9-1.jar:/home/hbase-1.2.2/lib/guava-12.0.1.jar:/home/hbase-1.2.2/lib/guice-3.0.jar:/home/hbase-1.2.2/lib/guice-servlet-3.0.jar:/home/hbase-1.2.2/lib/hadoop-annotations-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-auth-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-hdfs-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-app-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-core-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-api-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-server-common-2.5.1.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-client-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-examples-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-external-blockcache-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop2-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-prefix-tree-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-procedure-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-protocol-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-resource-bundle-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-rest-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-shell-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-thrift-1.2.2.jar:/home/hbase-1.2.2/lib/htrace-core-3.1.0-incubating.jar:/home/hbase-1.2.2/lib/httpclient-4.2.5.jar:/home/hbase-1.2.2/lib/httpcore-4.4.1.jar:/home/hbase-1.2.2/lib/jackson-core-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-jaxrs-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-mapper-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-xc-1.9.13.jar:/home/hbase-1.2.2/lib/jamon-runtime-2.4.1.jar:/home/hbase-1.2.2/lib/jasper-compiler-5.5.23.jar:/home/hbase-1.2.2/lib/jasper-runtime-5.5.23.jar:/home/hbase-1.2.2/lib/javax.inject-1.jar:/home/hbase-1.2.2/lib/java-xmlbuilder-0.4.jar:/home/hbase-1.2.2/lib/jaxb-api-2.2.2.jar:/home/hbase-1.2.2/lib/jaxb-impl-2.2.3-1.jar:/home/hbase-1.2.2/lib/jcodings-1.0.8.jar:/home/hbase-1.2.2/lib/jersey-client-1.9.jar:/home/hbase-1.2.2/lib/jersey-core-1.9.jar:/home/hbase-1.2.2/lib/jersey-guice-1.9.jar:/home/hbase-1.2.2/lib/jersey-json-1.9.jar:/home/hbase-1.2.2/lib/jersey-server-1.9.jar:/home/hbase-1.2.2/lib/jets3t-0.9.0.jar:/home/hbase-1.2.2/lib/jettison-1.3.3.jar:/home/hbase-1.2.2/lib/jetty-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-sslengine-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-util-6.1.26.jar:/home/hbase-1.2.2/lib/joni-2.1.2.jar:/home/hbase-1.2.2/lib/jruby-complete-1.6.8.jar:/home/hbase-1.2.2/lib/jsch-0.1.42.jar:/home/hbase-1.2.2/lib/jsp-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsp-api-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsr305-1.3.9.jar:/home/hbase-1.2.2/lib/junit-4.12.jar:/home/hbase-1.2.2/lib/leveldbjni-all-1.8.jar:/home/hbase-1.2.2/lib/libthrift-0.9.3.jar:/home/hbase-1.2.2/lib/log4j-1.2.17.jar:/home/hbase-1.2.2/lib/metrics-core-2.2.0.jar:/home/hbase-1.2.2/lib/nekohtml-1.9.16.jar:/home/hbase-1.2.2/lib/netty-all-4.0.23.Final.jar:/home/hbase-1.2.2/lib/paranamer-2.3.jar:/home/hbase-1.2.2/lib/protobuf-java-2.5.0.jar:/home/hbase-1.2.2/lib/servlet-api-2.5-6.1.14.jar:/home/hbase-1.2.2/lib/servlet-api-2.5.jar:/home/hbase-1.2.2/lib/slf4j-api-1.7.7.jar:/home/hbase-1.2.2/lib/slf4j-log4j12-1.7.5.jar:/home/hbase-1.2.2/lib/snappy-java-1.0.4.1.jar:/home/hbase-1.2.2/lib/spymemcached-2.11.6.jar:/home/hbase-1.2.2/lib/xalan-2.7.0.jar:/home/hbase-1.2.2/lib/xml-apis-1.3.03.jar:/home/hbase-1.2.2/lib/xml-apis-ext-1.3.04.jar:/home/hbase-1.2.2/lib/xmlenc-0.52.jar:/home/hbase-1.2.2/lib/xom-1.2.5.jar:/home/hbase-1.2.2/lib/xz-1.0.jar:/home/hbase-1.2.2/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/etc/hadoop:/home/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/hpme/hadoop-2.7.3/share/hadoop/mapreduce/*:/home/hadoop-2.7.3/contrib/capacity-scheduler/*.jar
2019-05-13 18:42:09,036 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop-2.7.3/lib/native
2019-05-13 18:42:09,036 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2019-05-13 18:42:09,036 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2019-05-13 18:42:09,036 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2019-05-13 18:42:09,036 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=i386
2019-05-13 18:42:09,037 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=3.10.0-957.12.1.el7.x86_64
2019-05-13 18:42:09,037 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=root
2019-05-13 18:42:09,037 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/root
2019-05-13 18:42:09,037 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hbase-1.2.2
2019-05-13 18:42:09,038 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=master:160000x0, quorum=localhost:2181, baseZNode=/hbase
2019-05-13 18:42:09,064 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2019-05-13 18:42:09,069 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session
2019-05-13 18:42:09,102 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x16ab212a1170000, negotiated timeout = 90000
2019-05-13 18:42:09,157 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2019-05-13 18:42:09,158 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: starting
2019-05-13 18:42:09,629 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-05-13 18:42:09,632 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2019-05-13 18:42:09,652 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2019-05-13 18:42:09,652 INFO  [main] http.HttpServer: Added global filter 'clickjackingprevention' (class=org.apache.hadoop.hbase.http.ClickjackingPreventionFilter)
2019-05-13 18:42:09,654 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2019-05-13 18:42:09,654 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-05-13 18:42:09,654 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-05-13 18:42:09,689 INFO  [main] http.HttpServer: Jetty bound to port 16010
2019-05-13 18:42:09,689 INFO  [main] mortbay.log: jetty-6.1.26
2019-05-13 18:42:10,198 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2019-05-13 18:42:10,202 INFO  [main] master.HMaster: hbase.rootdir=hdfs://master:9000/hbase, hbase.cluster.distributed=true
2019-05-13 18:42:10,226 INFO  [main] master.HMaster: Adding backup master ZNode /hbase/backup-masters/master,16000,1557765728280
2019-05-13 18:42:10,425 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/master,16000,1557765728280 from backup master directory
2019-05-13 18:42:10,457 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Registered Active Master=master,16000,1557765728280
2019-05-13 18:42:10,460 INFO  [master/master/192.168.178.37:16000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0xf70d83 connecting to ZooKeeper ensemble=localhost:2181
2019-05-13 18:42:10,460 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0xf70d830x0, quorum=localhost:2181, baseZNode=/hbase
2019-05-13 18:42:10,525 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2019-05-13 18:42:10,525 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2019-05-13 18:42:10,536 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16ab212a1170001, negotiated timeout = 90000
2019-05-13 18:42:10,537 INFO  [master/master/192.168.178.37:16000] client.ZooKeeperRegistry: ClusterId read in ZooKeeper is null
2019-05-13 18:42:10,598 FATAL [master:16000.activeMasterManager] master.HMaster: Failed to become active master
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setSafeMode(ClientNamenodeProtocolTranslatorPB.java:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.setSafeMode(DFSClient.java:2264)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:986)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:970)
	at org.apache.hadoop.hbase.util.FSUtils.isInSafeMode(FSUtils.java:525)
	at org.apache.hadoop.hbase.util.FSUtils.waitOnSafeMode(FSUtils.java:971)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:424)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:153)
	at org.apache.hadoop.hbase.master.MasterFileSystem.<init>(MasterFileSystem.java:128)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:652)
	at org.apache.hadoop.hbase.master.HMaster.access$600(HMaster.java:185)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1750)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 29 more
2019-05-13 18:42:10,608 FATAL [master:16000.activeMasterManager] master.HMaster: Unhandled exception. Starting shutdown.
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setSafeMode(ClientNamenodeProtocolTranslatorPB.java:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.setSafeMode(DFSClient.java:2264)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:986)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:970)
	at org.apache.hadoop.hbase.util.FSUtils.isInSafeMode(FSUtils.java:525)
	at org.apache.hadoop.hbase.util.FSUtils.waitOnSafeMode(FSUtils.java:971)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:424)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:153)
	at org.apache.hadoop.hbase.master.MasterFileSystem.<init>(MasterFileSystem.java:128)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:652)
	at org.apache.hadoop.hbase.master.HMaster.access$600(HMaster.java:185)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1750)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 29 more
2019-05-13 18:42:10,609 INFO  [master:16000.activeMasterManager] regionserver.HRegionServer: STOPPED: Unhandled exception. Starting shutdown.
2019-05-13 18:42:13,603 INFO  [master/master/192.168.178.37:16000] ipc.RpcServer: Stopping server on 16000
2019-05-13 18:42:13,604 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: stopping
2019-05-13 18:42:13,604 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: Stopping infoServer
2019-05-13 18:42:13,616 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2019-05-13 18:42:13,616 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2019-05-13 18:42:13,644 INFO  [master/master/192.168.178.37:16000] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:16010
2019-05-13 18:42:13,644 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1557765728280
2019-05-13 18:42:13,645 INFO  [master/master/192.168.178.37:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x16ab212a1170001
2019-05-13 18:42:13,649 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Session: 0x16ab212a1170001 closed
2019-05-13 18:42:13,651 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1557765728280; all regions closed.
2019-05-13 18:42:13,651 INFO  [master/master/192.168.178.37:16000-EventThread] zookeeper.ClientCnxn: EventThread shut down
2019-05-13 18:42:13,652 INFO  [master/master/192.168.178.37:16000] hbase.ChoreService: Chore service for: master,16000,1557765728280 had [] on shutdown
2019-05-13 18:42:13,658 INFO  [master/master/192.168.178.37:16000] ipc.RpcServer: Stopping server on 16000
2019-05-13 18:42:13,661 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Session: 0x16ab212a1170000 closed
2019-05-13 18:42:13,661 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1557765728280; zookeeper connection closed.
2019-05-13 18:42:13,661 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: master/master/192.168.178.37:16000 exiting
2019-05-13 18:42:13,661 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
Mo 13. Mai 18:43:34 CEST 2019 Stopping hbase (via master)
Mo 13. Mai 18:44:57 CEST 2019 Starting master on master
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 14923
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 14923
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2019-05-13 18:44:58,285 INFO  [main] util.VersionInfo: HBase 1.2.2
2019-05-13 18:44:58,286 INFO  [main] util.VersionInfo: Source code repository git://asf-dev/home/busbey/projects/hbase revision=3f671c1ead70d249ea4598f1bbcc5151322b3a13
2019-05-13 18:44:58,286 INFO  [main] util.VersionInfo: Compiled by busbey on Fri Jul  1 08:28:55 CDT 2016
2019-05-13 18:44:58,286 INFO  [main] util.VersionInfo: From source with checksum 7ac43c3d2f62f134b2a6aa1a05ad66ac
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:PATH=/home/jdk1.8.0_101/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/home/hadoop-2.7.3:/home/hadoop-2.7.3/bin/:/home/hbase-1.2.2/bin:/root/bin
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF_DIR=/home/hadoop-2.7.3/etc/hadoop
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:XDG_DATA_DIRS=/root/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/root
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/home/hadoop-2.7.3/lib/native
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:LOGNAME=root
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:PWD=/home/hbase-1.2.2
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:SELINUX_USE_CURRENT_RANGE=
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/home/hadoop-2.7.3
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -XX:PermSize=128m -XX:MaxPermSize=128m -Dhbase.log.dir=/home/hbase-1.2.2/logs -Dhbase.log.file=hbase-root-master-master.log -Dhbase.home.dir=/home/hbase-1.2.2 -Dhbase.id.str=root -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop-2.7.3/lib/native -Dhbase.security.logger=INFO,RFAS
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase-root-master.autorestart
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.Z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38;5;9:*.rar=38;5;9:*.alz=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.cab=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.axv=38;5;13:*.anx=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-root-master-master.log
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/home/jdk1.8.0_101
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:TERM=xterm-256color
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:LANG=de_DE.UTF-8
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=2
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:SELINUX_LEVEL_REQUESTED=
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:SELINUX_ROLE_REQUESTED=
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:YARN_HOME=/home/hadoop-2.7.3
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HADOOP_HDFS_HOME=/home/hadoop-2.7.3
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HADOOP_MAPRED_HOME=/hpme/hadoop-2.7.3
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_HOME=/home/hadoop-2.7.3
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=root
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase-root-master.znode
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:SSH_TTY=/dev/pts/0
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=192.168.178.62 53746 22
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-root-master-master
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hbase-1.2.2/logs
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:USER=root
2019-05-13 18:44:58,603 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hbase-1.2.2/conf:/home/jdk1.8.0_101/lib/tools.jar:/home/hbase-1.2.2:/home/hbase-1.2.2/lib/activation-1.1.jar:/home/hbase-1.2.2/lib/antisamy-1.5.3.jar:/home/hbase-1.2.2/lib/aopalliance-1.0.jar:/home/hbase-1.2.2/lib/apacheds-i18n-2.0.0-M15.jar:/home/hbase-1.2.2/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hbase-1.2.2/lib/api-asn1-api-1.0.0-M20.jar:/home/hbase-1.2.2/lib/api-util-1.0.0-M20.jar:/home/hbase-1.2.2/lib/asm-3.1.jar:/home/hbase-1.2.2/lib/avro-1.7.4.jar:/home/hbase-1.2.2/lib/batik-css-1.8.jar:/home/hbase-1.2.2/lib/batik-ext-1.8.jar:/home/hbase-1.2.2/lib/batik-util-1.8.jar:/home/hbase-1.2.2/lib/bsh-core-2.0b4.jar:/home/hbase-1.2.2/lib/commons-beanutils-1.7.0.jar:/home/hbase-1.2.2/lib/commons-beanutils-core-1.8.3.jar:/home/hbase-1.2.2/lib/commons-cli-1.2.jar:/home/hbase-1.2.2/lib/commons-codec-1.9.jar:/home/hbase-1.2.2/lib/commons-collections-3.2.2.jar:/home/hbase-1.2.2/lib/commons-compress-1.4.1.jar:/home/hbase-1.2.2/lib/commons-configuration-1.6.jar:/home/hbase-1.2.2/lib/commons-daemon-1.0.13.jar:/home/hbase-1.2.2/lib/commons-digester-1.8.jar:/home/hbase-1.2.2/lib/commons-el-1.0.jar:/home/hbase-1.2.2/lib/commons-fileupload-1.3.1.jar:/home/hbase-1.2.2/lib/commons-httpclient-3.1.jar:/home/hbase-1.2.2/lib/commons-io-2.4.jar:/home/hbase-1.2.2/lib/commons-lang-2.6.jar:/home/hbase-1.2.2/lib/commons-logging-1.2.jar:/home/hbase-1.2.2/lib/commons-math-2.2.jar:/home/hbase-1.2.2/lib/commons-math3-3.1.1.jar:/home/hbase-1.2.2/lib/commons-net-3.1.jar:/home/hbase-1.2.2/lib/disruptor-3.3.0.jar:/home/hbase-1.2.2/lib/esapi-2.1.0.1.jar:/home/hbase-1.2.2/lib/findbugs-annotations-1.3.9-1.jar:/home/hbase-1.2.2/lib/guava-12.0.1.jar:/home/hbase-1.2.2/lib/guice-3.0.jar:/home/hbase-1.2.2/lib/guice-servlet-3.0.jar:/home/hbase-1.2.2/lib/hadoop-annotations-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-auth-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-hdfs-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-app-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-core-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-api-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-server-common-2.5.1.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-client-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-examples-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-external-blockcache-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop2-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-prefix-tree-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-procedure-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-protocol-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-resource-bundle-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-rest-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-shell-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-thrift-1.2.2.jar:/home/hbase-1.2.2/lib/htrace-core-3.1.0-incubating.jar:/home/hbase-1.2.2/lib/httpclient-4.2.5.jar:/home/hbase-1.2.2/lib/httpcore-4.4.1.jar:/home/hbase-1.2.2/lib/jackson-core-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-jaxrs-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-mapper-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-xc-1.9.13.jar:/home/hbase-1.2.2/lib/jamon-runtime-2.4.1.jar:/home/hbase-1.2.2/lib/jasper-compiler-5.5.23.jar:/home/hbase-1.2.2/lib/jasper-runtime-5.5.23.jar:/home/hbase-1.2.2/lib/javax.inject-1.jar:/home/hbase-1.2.2/lib/java-xmlbuilder-0.4.jar:/home/hbase-1.2.2/lib/jaxb-api-2.2.2.jar:/home/hbase-1.2.2/lib/jaxb-impl-2.2.3-1.jar:/home/hbase-1.2.2/lib/jcodings-1.0.8.jar:/home/hbase-1.2.2/lib/jersey-client-1.9.jar:/home/hbase-1.2.2/lib/jersey-core-1.9.jar:/home/hbase-1.2.2/lib/jersey-guice-1.9.jar:/home/hbase-1.2.2/lib/jersey-json-1.9.jar:/home/hbase-1.2.2/lib/jersey-server-1.9.jar:/home/hbase-1.2.2/lib/jets3t-0.9.0.jar:/home/hbase-1.2.2/lib/jettison-1.3.3.jar:/home/hbase-1.2.2/lib/jetty-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-sslengine-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-util-6.1.26.jar:/home/hbase-1.2.2/lib/joni-2.1.2.jar:/home/hbase-1.2.2/lib/jruby-complete-1.6.8.jar:/home/hbase-1.2.2/lib/jsch-0.1.42.jar:/home/hbase-1.2.2/lib/jsp-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsp-api-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsr305-1.3.9.jar:/home/hbase-1.2.2/lib/junit-4.12.jar:/home/hbase-1.2.2/lib/leveldbjni-all-1.8.jar:/home/hbase-1.2.2/lib/libthrift-0.9.3.jar:/home/hbase-1.2.2/lib/log4j-1.2.17.jar:/home/hbase-1.2.2/lib/metrics-core-2.2.0.jar:/home/hbase-1.2.2/lib/nekohtml-1.9.16.jar:/home/hbase-1.2.2/lib/netty-all-4.0.23.Final.jar:/home/hbase-1.2.2/lib/paranamer-2.3.jar:/home/hbase-1.2.2/lib/protobuf-java-2.5.0.jar:/home/hbase-1.2.2/lib/servlet-api-2.5-6.1.14.jar:/home/hbase-1.2.2/lib/servlet-api-2.5.jar:/home/hbase-1.2.2/lib/slf4j-api-1.7.7.jar:/home/hbase-1.2.2/lib/slf4j-log4j12-1.7.5.jar:/home/hbase-1.2.2/lib/snappy-java-1.0.4.1.jar:/home/hbase-1.2.2/lib/spymemcached-2.11.6.jar:/home/hbase-1.2.2/lib/xalan-2.7.0.jar:/home/hbase-1.2.2/lib/xml-apis-1.3.03.jar:/home/hbase-1.2.2/lib/xml-apis-ext-1.3.04.jar:/home/hbase-1.2.2/lib/xmlenc-0.52.jar:/home/hbase-1.2.2/lib/xom-1.2.5.jar:/home/hbase-1.2.2/lib/xz-1.0.jar:/home/hbase-1.2.2/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/etc/hadoop:/home/hadoop-2.7.3/share/hadoop/common/lib/*:/home/hadoop-2.7.3/share/hadoop/common/*:/home/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/*:/home/hadoop-2.7.3/share/hadoop/hdfs/*:/home/hadoop-2.7.3/share/hadoop/yarn/lib/*:/home/hadoop-2.7.3/share/hadoop/yarn/*:/hpme/hadoop-2.7.3/share/hadoop/mapreduce/*:/home/hadoop-2.7.3/contrib/capacity-scheduler/*.jar
2019-05-13 18:44:58,604 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=192.168.178.62 53746 192.168.178.37 22
2019-05-13 18:44:58,604 INFO  [main] util.ServerCommandLine: env:HOSTNAME=master
2019-05-13 18:44:58,604 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2019-05-13 18:44:58,604 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/0
2019-05-13 18:44:58,604 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2019-05-13 18:44:58,604 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hbase-1.2.2
2019-05-13 18:44:58,604 INFO  [main] util.ServerCommandLine: env:HOME=/root
2019-05-13 18:44:58,604 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2019-05-13 18:44:58,605 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) Client VM, vmVendor=Oracle Corporation, vmVersion=25.101-b13
2019-05-13 18:44:58,605 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -XX:+UseConcMarkSweepGC, -XX:PermSize=128m, -XX:MaxPermSize=128m, -Dhbase.log.dir=/home/hbase-1.2.2/logs, -Dhbase.log.file=hbase-root-master-master.log, -Dhbase.home.dir=/home/hbase-1.2.2, -Dhbase.id.str=root, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop-2.7.3/lib/native, -Dhbase.security.logger=INFO,RFAS]
2019-05-13 18:44:58,749 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-05-13 18:44:58,953 INFO  [main] regionserver.RSRpcServices: master/master/192.168.178.37:16000 server-side HConnection retries=350
2019-05-13 18:44:59,111 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2019-05-13 18:44:59,138 INFO  [main] ipc.RpcServer: master/master/192.168.178.37:16000: started 10 reader(s) listening on port=16000
2019-05-13 18:44:59,230 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2019-05-13 18:44:59,302 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-05-13 18:44:59,302 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2019-05-13 18:44:59,722 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2019-05-13 18:44:59,856 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16000 connecting to ZooKeeper ensemble=localhost:2181
2019-05-13 18:44:59,862 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2019-05-13 18:44:59,862 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=master
2019-05-13 18:44:59,862 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_101
2019-05-13 18:44:59,862 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2019-05-13 18:44:59,862 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/home/jdk1.8.0_101/jre
2019-05-13 18:44:59,862 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hbase-1.2.2/conf:/home/jdk1.8.0_101/lib/tools.jar:/home/hbase-1.2.2:/home/hbase-1.2.2/lib/activation-1.1.jar:/home/hbase-1.2.2/lib/antisamy-1.5.3.jar:/home/hbase-1.2.2/lib/aopalliance-1.0.jar:/home/hbase-1.2.2/lib/apacheds-i18n-2.0.0-M15.jar:/home/hbase-1.2.2/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hbase-1.2.2/lib/api-asn1-api-1.0.0-M20.jar:/home/hbase-1.2.2/lib/api-util-1.0.0-M20.jar:/home/hbase-1.2.2/lib/asm-3.1.jar:/home/hbase-1.2.2/lib/avro-1.7.4.jar:/home/hbase-1.2.2/lib/batik-css-1.8.jar:/home/hbase-1.2.2/lib/batik-ext-1.8.jar:/home/hbase-1.2.2/lib/batik-util-1.8.jar:/home/hbase-1.2.2/lib/bsh-core-2.0b4.jar:/home/hbase-1.2.2/lib/commons-beanutils-1.7.0.jar:/home/hbase-1.2.2/lib/commons-beanutils-core-1.8.3.jar:/home/hbase-1.2.2/lib/commons-cli-1.2.jar:/home/hbase-1.2.2/lib/commons-codec-1.9.jar:/home/hbase-1.2.2/lib/commons-collections-3.2.2.jar:/home/hbase-1.2.2/lib/commons-compress-1.4.1.jar:/home/hbase-1.2.2/lib/commons-configuration-1.6.jar:/home/hbase-1.2.2/lib/commons-daemon-1.0.13.jar:/home/hbase-1.2.2/lib/commons-digester-1.8.jar:/home/hbase-1.2.2/lib/commons-el-1.0.jar:/home/hbase-1.2.2/lib/commons-fileupload-1.3.1.jar:/home/hbase-1.2.2/lib/commons-httpclient-3.1.jar:/home/hbase-1.2.2/lib/commons-io-2.4.jar:/home/hbase-1.2.2/lib/commons-lang-2.6.jar:/home/hbase-1.2.2/lib/commons-logging-1.2.jar:/home/hbase-1.2.2/lib/commons-math-2.2.jar:/home/hbase-1.2.2/lib/commons-math3-3.1.1.jar:/home/hbase-1.2.2/lib/commons-net-3.1.jar:/home/hbase-1.2.2/lib/disruptor-3.3.0.jar:/home/hbase-1.2.2/lib/esapi-2.1.0.1.jar:/home/hbase-1.2.2/lib/findbugs-annotations-1.3.9-1.jar:/home/hbase-1.2.2/lib/guava-12.0.1.jar:/home/hbase-1.2.2/lib/guice-3.0.jar:/home/hbase-1.2.2/lib/guice-servlet-3.0.jar:/home/hbase-1.2.2/lib/hadoop-annotations-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-auth-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-hdfs-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-app-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-core-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-api-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-client-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-common-2.5.1.jar:/home/hbase-1.2.2/lib/hadoop-yarn-server-common-2.5.1.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-annotations-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-client-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-common-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-examples-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-external-blockcache-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop2-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-hadoop-compat-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-it-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-prefix-tree-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-procedure-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-protocol-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-resource-bundle-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-rest-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-server-1.2.2-tests.jar:/home/hbase-1.2.2/lib/hbase-shell-1.2.2.jar:/home/hbase-1.2.2/lib/hbase-thrift-1.2.2.jar:/home/hbase-1.2.2/lib/htrace-core-3.1.0-incubating.jar:/home/hbase-1.2.2/lib/httpclient-4.2.5.jar:/home/hbase-1.2.2/lib/httpcore-4.4.1.jar:/home/hbase-1.2.2/lib/jackson-core-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-jaxrs-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-mapper-asl-1.9.13.jar:/home/hbase-1.2.2/lib/jackson-xc-1.9.13.jar:/home/hbase-1.2.2/lib/jamon-runtime-2.4.1.jar:/home/hbase-1.2.2/lib/jasper-compiler-5.5.23.jar:/home/hbase-1.2.2/lib/jasper-runtime-5.5.23.jar:/home/hbase-1.2.2/lib/javax.inject-1.jar:/home/hbase-1.2.2/lib/java-xmlbuilder-0.4.jar:/home/hbase-1.2.2/lib/jaxb-api-2.2.2.jar:/home/hbase-1.2.2/lib/jaxb-impl-2.2.3-1.jar:/home/hbase-1.2.2/lib/jcodings-1.0.8.jar:/home/hbase-1.2.2/lib/jersey-client-1.9.jar:/home/hbase-1.2.2/lib/jersey-core-1.9.jar:/home/hbase-1.2.2/lib/jersey-guice-1.9.jar:/home/hbase-1.2.2/lib/jersey-json-1.9.jar:/home/hbase-1.2.2/lib/jersey-server-1.9.jar:/home/hbase-1.2.2/lib/jets3t-0.9.0.jar:/home/hbase-1.2.2/lib/jettison-1.3.3.jar:/home/hbase-1.2.2/lib/jetty-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-sslengine-6.1.26.jar:/home/hbase-1.2.2/lib/jetty-util-6.1.26.jar:/home/hbase-1.2.2/lib/joni-2.1.2.jar:/home/hbase-1.2.2/lib/jruby-complete-1.6.8.jar:/home/hbase-1.2.2/lib/jsch-0.1.42.jar:/home/hbase-1.2.2/lib/jsp-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsp-api-2.1-6.1.14.jar:/home/hbase-1.2.2/lib/jsr305-1.3.9.jar:/home/hbase-1.2.2/lib/junit-4.12.jar:/home/hbase-1.2.2/lib/leveldbjni-all-1.8.jar:/home/hbase-1.2.2/lib/libthrift-0.9.3.jar:/home/hbase-1.2.2/lib/log4j-1.2.17.jar:/home/hbase-1.2.2/lib/metrics-core-2.2.0.jar:/home/hbase-1.2.2/lib/nekohtml-1.9.16.jar:/home/hbase-1.2.2/lib/netty-all-4.0.23.Final.jar:/home/hbase-1.2.2/lib/paranamer-2.3.jar:/home/hbase-1.2.2/lib/protobuf-java-2.5.0.jar:/home/hbase-1.2.2/lib/servlet-api-2.5-6.1.14.jar:/home/hbase-1.2.2/lib/servlet-api-2.5.jar:/home/hbase-1.2.2/lib/slf4j-api-1.7.7.jar:/home/hbase-1.2.2/lib/slf4j-log4j12-1.7.5.jar:/home/hbase-1.2.2/lib/snappy-java-1.0.4.1.jar:/home/hbase-1.2.2/lib/spymemcached-2.11.6.jar:/home/hbase-1.2.2/lib/xalan-2.7.0.jar:/home/hbase-1.2.2/lib/xml-apis-1.3.03.jar:/home/hbase-1.2.2/lib/xml-apis-ext-1.3.04.jar:/home/hbase-1.2.2/lib/xmlenc-0.52.jar:/home/hbase-1.2.2/lib/xom-1.2.5.jar:/home/hbase-1.2.2/lib/xz-1.0.jar:/home/hbase-1.2.2/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/etc/hadoop:/home/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/hpme/hadoop-2.7.3/share/hadoop/mapreduce/*:/home/hadoop-2.7.3/contrib/capacity-scheduler/*.jar
2019-05-13 18:44:59,863 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop-2.7.3/lib/native
2019-05-13 18:44:59,863 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2019-05-13 18:44:59,863 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2019-05-13 18:44:59,863 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2019-05-13 18:44:59,863 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=i386
2019-05-13 18:44:59,863 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=3.10.0-957.12.1.el7.x86_64
2019-05-13 18:44:59,863 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=root
2019-05-13 18:44:59,863 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/root
2019-05-13 18:44:59,863 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hbase-1.2.2
2019-05-13 18:44:59,865 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=master:160000x0, quorum=localhost:2181, baseZNode=/hbase
2019-05-13 18:44:59,877 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2019-05-13 18:44:59,880 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2019-05-13 18:44:59,902 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16ab2153d450000, negotiated timeout = 90000
2019-05-13 18:44:59,945 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2019-05-13 18:44:59,945 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: starting
2019-05-13 18:45:00,040 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-05-13 18:45:00,043 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2019-05-13 18:45:00,052 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2019-05-13 18:45:00,052 INFO  [main] http.HttpServer: Added global filter 'clickjackingprevention' (class=org.apache.hadoop.hbase.http.ClickjackingPreventionFilter)
2019-05-13 18:45:00,054 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2019-05-13 18:45:00,054 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-05-13 18:45:00,054 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-05-13 18:45:00,068 INFO  [main] http.HttpServer: Jetty bound to port 16010
2019-05-13 18:45:00,068 INFO  [main] mortbay.log: jetty-6.1.26
2019-05-13 18:45:00,304 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2019-05-13 18:45:00,307 INFO  [main] master.HMaster: hbase.rootdir=hdfs://master:9000/hbase, hbase.cluster.distributed=true
2019-05-13 18:45:00,317 INFO  [main] master.HMaster: Adding backup master ZNode /hbase/backup-masters/master,16000,1557765899317
2019-05-13 18:45:00,391 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/master,16000,1557765899317 from backup master directory
2019-05-13 18:45:00,408 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Registered Active Master=master,16000,1557765899317
2019-05-13 18:45:00,474 INFO  [master/master/192.168.178.37:16000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x38d6fb connecting to ZooKeeper ensemble=localhost:2181
2019-05-13 18:45:00,474 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x38d6fb0x0, quorum=localhost:2181, baseZNode=/hbase
2019-05-13 18:45:00,476 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2019-05-13 18:45:00,476 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2019-05-13 18:45:00,480 INFO  [master/master/192.168.178.37:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16ab2153d450001, negotiated timeout = 90000
2019-05-13 18:45:00,481 INFO  [master/master/192.168.178.37:16000] client.ZooKeeperRegistry: ClusterId read in ZooKeeper is null
2019-05-13 18:45:00,894 INFO  [master:16000.activeMasterManager] util.FSUtils: Created version file at hdfs://master:9000/hbase with version=8
2019-05-13 18:45:01,007 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: BOOTSTRAP: creating hbase:meta region
2019-05-13 18:45:01,009 INFO  [master:16000.activeMasterManager] regionserver.HRegion: creating HRegion hbase:meta HTD == 'hbase:meta', {TABLE_ATTRIBUTES => {IS_META => 'true', coprocessor$1 => '|org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint|536870911|'}, {NAME => 'info', BLOOMFILTER => 'NONE', VERSIONS => '10', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'false', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'} RootDir = hdfs://master:9000/hbase Table name == hbase:meta
2019-05-13 18:45:01,218 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig: Allocating LruBlockCache size=99.85 MB, blockSize=64 KB
2019-05-13 18:45:01,249 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig: Created cacheConfig for info: blockCache=LruBlockCache{blockCount=0, currentSize=62352, freeSize=104637960, maxSize=104700312, heapSize=62352, minSize=99465296, minFactor=0.95, multiSize=49732648, multiFactor=0.5, singleSize=24866324, singleFactor=0.25}, cacheDataOnRead=false, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false
2019-05-13 18:45:01,258 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807, 9223372036854775807); files [3, 10); ratio 1,200000; off-peak ratio 5,000000; throttle point 2684354560; major period 604800000, major jitter 0,500000, min locality to compact 0,000000
2019-05-13 18:45:01,310 INFO  [master:16000.activeMasterManager] regionserver.HRegion: Onlined 1588230740; next sequenceid=2
2019-05-13 18:45:01,311 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore: Closed info
2019-05-13 18:45:01,311 INFO  [master:16000.activeMasterManager] regionserver.HRegion: Closed hbase:meta,,1.1588230740
2019-05-13 18:45:01,357 INFO  [master:16000.activeMasterManager] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2019-05-13 18:45:01,367 INFO  [master:16000.activeMasterManager] coordination.SplitLogManagerCoordination: Found 0 orphan tasks and 0 rescan nodes
2019-05-13 18:45:01,382 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0xf9a44d connecting to ZooKeeper ensemble=localhost:2181
2019-05-13 18:45:01,382 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0xf9a44d0x0, quorum=localhost:2181, baseZNode=/hbase
2019-05-13 18:45:01,383 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2019-05-13 18:45:01,383 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2019-05-13 18:45:01,385 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16ab2153d450002, negotiated timeout = 90000
2019-05-13 18:45:01,393 INFO  [master:16000.activeMasterManager] balancer.StochasticLoadBalancer: loading config
2019-05-13 18:45:01,441 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: ClusterId : c583b292-6510-48bf-8ffd-11b243e23d6c
2019-05-13 18:45:01,451 INFO  [master:16000.activeMasterManager] master.HMaster: Server active/primary master=master,16000,1557765899317, sessionid=0x16ab2153d450000, setting cluster-up flag (Was=false)
2019-05-13 18:45:01,521 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/flush-table-proc/acquired /hbase/flush-table-proc/reached /hbase/flush-table-proc/abort
2019-05-13 18:45:01,539 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2019-05-13 18:45:01,580 INFO  [master:16000.activeMasterManager] master.MasterCoprocessorHost: System coprocessor loading is enabled
2019-05-13 18:45:01,629 INFO  [master:16000.activeMasterManager] procedure2.ProcedureExecutor: Starting procedure executor threads=5
2019-05-13 18:45:01,629 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Starting WAL Procedure Store lease recovery
2019-05-13 18:45:01,630 WARN  [master:16000.activeMasterManager] wal.WALProcedureStore: Log directory not found: File hdfs://master:9000/hbase/MasterProcWALs does not exist.
2019-05-13 18:45:01,649 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Lease acquired for flushLogId: 1
2019-05-13 18:45:01,719 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=localhost:2181
2019-05-13 18:45:01,719 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=replicationLogCleaner0x0, quorum=localhost:2181, baseZNode=/hbase
2019-05-13 18:45:01,738 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2019-05-13 18:45:01,739 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2019-05-13 18:45:01,753 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16ab2153d450003, negotiated timeout = 90000
2019-05-13 18:45:01,845 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2019-05-13 18:45:01,894 INFO  [WALProcedureStoreSyncThread] wal.WALProcedureStore: Remove log: hdfs://master:9000/hbase/MasterProcWALs/state-00000000000000000001.log
2019-05-13 18:45:01,894 INFO  [WALProcedureStoreSyncThread] wal.WALProcedureStore: Removed logs: [hdfs://master:9000/hbase/MasterProcWALs/state-00000000000000000002.log]
2019-05-13 18:45:01,924 INFO  [B.defaultRpcServer.handler=1,queue=1,port=16000] master.ServerManager: Registering server=master,16201,1557765730959
2019-05-13 18:45:01,958 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 113 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2019-05-13 18:45:03,481 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 1636 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2019-05-13 18:45:05,003 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 3158 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2019-05-13 18:45:06,368 INFO  [master:16000.activeMasterManager] master.ServerManager: Finished waiting for region servers count to settle; checked in 1, slept for 4523 ms, expecting minimum of 1, maximum of 2147483647, master is running
2019-05-13 18:45:06,374 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: Log folder hdfs://master:9000/hbase/WALs/master,16201,1557765730959 belongs to an existing region server
2019-05-13 18:45:07,191 INFO  [master:16000.activeMasterManager] zookeeper.MetaTableLocator: Deleting hbase:meta region location in ZooKeeper
2019-05-13 18:45:07,197 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Setting node as OFFLINED in ZooKeeper for region {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2019-05-13 18:45:07,207 INFO  [master:16000.activeMasterManager] zookeeper.ZKTableStateManager: Moving table hbase:meta state from null to ENABLED
2019-05-13 18:45:07,215 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to master,16201,1557765730959
2019-05-13 18:45:07,215 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {1588230740 state=OFFLINE, ts=1557765907198, server=null} to {1588230740 state=PENDING_OPEN, ts=1557765907215, server=master,16201,1557765730959}
2019-05-13 18:45:07,283 INFO  [master:16000.activeMasterManager] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2019-05-13 18:45:07,354 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transition {1588230740 state=PENDING_OPEN, ts=1557765907215, server=master,16201,1557765730959} to {1588230740 state=OPENING, ts=1557765907354, server=master,16201,1557765730959}
2019-05-13 18:45:08,478 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transition {1588230740 state=OPENING, ts=1557765907354, server=master,16201,1557765730959} to {1588230740 state=OPEN, ts=1557765908478, server=master,16201,1557765730959}
2019-05-13 18:45:08,480 INFO  [AM.ZK.Worker-pool2-t2] coordination.ZkOpenRegionCoordination: Handling OPENED of 1588230740 from master,16000,1557765899317; deleting unassigned node
2019-05-13 18:45:08,488 INFO  [master:16000.activeMasterManager] master.HMaster: hbase:meta with replicaId 0 assigned=1, rit=false, location=master,16201,1557765730959
2019-05-13 18:45:08,622 INFO  [master:16000.activeMasterManager] hbase.MetaMigrationConvertingToPB: hbase:meta doesn't have any entries to update.
2019-05-13 18:45:08,622 INFO  [master:16000.activeMasterManager] hbase.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2019-05-13 18:45:08,629 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Clean cluster startup. Assigning user regions
2019-05-13 18:45:08,630 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Joined the cluster in 7ms, failover=false
2019-05-13 18:45:08,646 INFO  [master:16000.activeMasterManager] master.TableNamespaceManager: Namespace table not found. Creating...
2019-05-13 18:45:08,964 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: creating HRegion hbase:namespace HTD == 'hbase:namespace', {NAME => 'info', BLOOMFILTER => 'ROW', VERSIONS => '10', IN_MEMORY => 'true', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', CACHE_DATA_IN_L1 => 'true', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'} RootDir = hdfs://master:9000/hbase/.tmp Table name == hbase:namespace
2019-05-13 18:45:08,985 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: Closed hbase:namespace,,1557765908646.85da2a950d3d005ad03c657436f29eea.
2019-05-13 18:45:09,188 INFO  [ProcedureExecutor-0] hbase.MetaTableAccessor: Added 1
2019-05-13 18:45:09,295 INFO  [ProcedureExecutor-0] zookeeper.ZKTableStateManager: Moving table hbase:namespace state from null to ENABLING
2019-05-13 18:45:09,299 INFO  [ProcedureExecutor-0] master.AssignmentManager: Assigning 1 region(s) to master,16201,1557765730959
2019-05-13 18:45:09,306 INFO  [ProcedureExecutor-0] master.RegionStates: Transition {85da2a950d3d005ad03c657436f29eea state=OFFLINE, ts=1557765909300, server=null} to {85da2a950d3d005ad03c657436f29eea state=PENDING_OPEN, ts=1557765909306, server=master,16201,1557765730959}
2019-05-13 18:45:09,350 INFO  [ProcedureExecutor-0] zookeeper.ZKTableStateManager: Moving table hbase:namespace state from ENABLING to ENABLED
2019-05-13 18:45:09,358 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transition {85da2a950d3d005ad03c657436f29eea state=PENDING_OPEN, ts=1557765909306, server=master,16201,1557765730959} to {85da2a950d3d005ad03c657436f29eea state=OPENING, ts=1557765909358, server=master,16201,1557765730959}
2019-05-13 18:45:09,481 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transition {85da2a950d3d005ad03c657436f29eea state=OPENING, ts=1557765909358, server=master,16201,1557765730959} to {85da2a950d3d005ad03c657436f29eea state=OPEN, ts=1557765909481, server=master,16201,1557765730959}
2019-05-13 18:45:09,646 INFO  [master:16000.activeMasterManager] master.HMaster: Master has completed initialization
2019-05-13 18:45:09,656 INFO  [master:16000.activeMasterManager] quotas.MasterQuotaManager: Quota support disabled
2019-05-13 18:45:09,657 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeperWatcher: not a secure deployment, proceeding
2019-05-13 18:45:31,847 INFO  [WALProcedureStoreSyncThread] wal.WALProcedureStore: Remove log: hdfs://master:9000/hbase/MasterProcWALs/state-00000000000000000002.log
2019-05-13 18:45:31,847 INFO  [WALProcedureStoreSyncThread] wal.WALProcedureStore: Removed logs: [hdfs://master:9000/hbase/MasterProcWALs/state-00000000000000000003.log]
2019-05-13 18:50:01,251 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=29, evicted=0, evictedPerRun=0.0
2019-05-13 18:55:01,248 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=59, evicted=0, evictedPerRun=0.0
2019-05-13 19:00:01,247 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=89, evicted=0, evictedPerRun=0.0
2019-05-13 19:05:01,256 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=119, evicted=0, evictedPerRun=0.0
2019-05-13 19:10:01,250 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=149, evicted=0, evictedPerRun=0.0
2019-05-13 19:15:01,248 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=179, evicted=0, evictedPerRun=0.0
2019-05-13 19:20:01,256 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=209, evicted=0, evictedPerRun=0.0
2019-05-13 19:25:01,257 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=239, evicted=0, evictedPerRun=0.0
2019-05-13 19:30:01,249 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=269, evicted=0, evictedPerRun=0.0
2019-05-13 19:35:01,255 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=299, evicted=0, evictedPerRun=0.0
2019-05-13 19:40:01,250 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=329, evicted=0, evictedPerRun=0.0
2019-05-13 19:45:01,248 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=359, evicted=0, evictedPerRun=0.0
2019-05-13 19:45:31,881 INFO  [WALProcedureStoreSyncThread] wal.WALProcedureStore: Remove log: hdfs://master:9000/hbase/MasterProcWALs/state-00000000000000000003.log
2019-05-13 19:45:31,882 INFO  [WALProcedureStoreSyncThread] wal.WALProcedureStore: Removed logs: [hdfs://master:9000/hbase/MasterProcWALs/state-00000000000000000004.log]
2019-05-13 19:50:01,252 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=389, evicted=0, evictedPerRun=0.0
2019-05-13 19:55:01,253 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=419, evicted=0, evictedPerRun=0.0
2019-05-13 20:00:01,249 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=449, evicted=0, evictedPerRun=0.0
2019-05-13 20:05:01,248 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=479, evicted=0, evictedPerRun=0.0
2019-05-13 20:10:01,250 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=509, evicted=0, evictedPerRun=0.0
2019-05-13 20:15:01,249 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=539, evicted=0, evictedPerRun=0.0
2019-05-13 20:20:01,253 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=60.89 KB, freeSize=99.79 MB, max=99.85 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=569, evicted=0, evictedPerRun=0.0
2019-05-13 20:22:53,624 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 30 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:22:54,628 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 31 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:22:55,633 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 32 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:22:56,635 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 33 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:22:57,640 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 34 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:22:58,644 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 35 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:22:59,645 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 36 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:00,649 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 37 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:01,653 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 38 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:01,819 WARN  [master,16000,1557765899317_ChoreService_1] cleaner.CleanerChore: Error while cleaning the logs
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:523)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1766)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1749)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:643)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:101)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:705)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:701)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:701)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1722)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1742)
	at org.apache.hadoop.hbase.master.cleaner.CleanerChore.chore(CleanerChore.java:123)
	at org.apache.hadoop.hbase.ScheduledChore.run(ScheduledChore.java:185)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at org.apache.hadoop.hbase.JitterScheduledThreadPoolExecutorImpl$JitteredRunnableScheduledFuture.run(JitterScheduledThreadPoolExecutorImpl.java:110)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 40 more
2019-05-13 20:23:01,846 WARN  [master,16000,1557765899317_ChoreService_1] cleaner.CleanerChore: Error while cleaning the logs
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:523)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1766)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1749)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:643)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:101)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:705)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:701)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:701)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1722)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1742)
	at org.apache.hadoop.hbase.master.cleaner.CleanerChore.chore(CleanerChore.java:123)
	at org.apache.hadoop.hbase.ScheduledChore.run(ScheduledChore.java:185)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at org.apache.hadoop.hbase.JitterScheduledThreadPoolExecutorImpl$JitteredRunnableScheduledFuture.run(JitterScheduledThreadPoolExecutorImpl.java:110)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 40 more
2019-05-13 20:23:02,659 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 39 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:03,661 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 40 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:04,662 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 41 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:05,665 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 42 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:06,668 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 43 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:07,670 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 44 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor9.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
Mo 13. Mai 20:23:08 CEST 2019 Stopping hbase (via master)
2019-05-13 20:23:08,677 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 45 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor9.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:08,870 WARN  [region-location-2] balancer.RegionLocationFinder: IOException during HDFSBlocksDistribution computation. for region = 1588230740
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor9.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:523)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1766)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1749)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:643)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:101)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:705)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:701)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:701)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1722)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1742)
	at org.apache.hadoop.hbase.regionserver.HRegionFileSystem.getStoreFiles(HRegionFileSystem.java:199)
	at org.apache.hadoop.hbase.regionserver.HRegionFileSystem.getStoreFiles(HRegionFileSystem.java:187)
	at org.apache.hadoop.hbase.regionserver.HRegion.computeHDFSBlocksDistribution(HRegion.java:1071)
	at org.apache.hadoop.hbase.regionserver.HRegion.computeHDFSBlocksDistribution(HRegion.java:1051)
	at org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.internalGetTopBlockLocation(RegionLocationFinder.java:186)
	at org.apache.hadoop.hbase.master.balancer.RegionLocationFinder$1$1.call(RegionLocationFinder.java:80)
	at org.apache.hadoop.hbase.master.balancer.RegionLocationFinder$1$1.call(RegionLocationFinder.java:77)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 45 more
2019-05-13 20:23:08,871 WARN  [region-location-4] balancer.RegionLocationFinder: IOException during HDFSBlocksDistribution computation. for region = 85da2a950d3d005ad03c657436f29eea
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor9.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:523)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1766)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1749)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:643)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:101)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:705)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:701)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:701)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1722)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1742)
	at org.apache.hadoop.hbase.regionserver.HRegionFileSystem.getStoreFiles(HRegionFileSystem.java:199)
	at org.apache.hadoop.hbase.regionserver.HRegionFileSystem.getStoreFiles(HRegionFileSystem.java:187)
	at org.apache.hadoop.hbase.regionserver.HRegion.computeHDFSBlocksDistribution(HRegion.java:1071)
	at org.apache.hadoop.hbase.regionserver.HRegion.computeHDFSBlocksDistribution(HRegion.java:1051)
	at org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.internalGetTopBlockLocation(RegionLocationFinder.java:186)
	at org.apache.hadoop.hbase.master.balancer.RegionLocationFinder$1$1.call(RegionLocationFinder.java:80)
	at org.apache.hadoop.hbase.master.balancer.RegionLocationFinder$1$1.call(RegionLocationFinder.java:77)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 45 more
2019-05-13 20:23:09,679 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 46 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor9.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:09,857 INFO  [B.defaultRpcServer.handler=18,queue=0,port=16000] master.MasterRpcServices: Client=root//192.168.178.37 shutdown
2019-05-13 20:23:09,857 INFO  [B.defaultRpcServer.handler=18,queue=0,port=16000] regionserver.HRegionServer: STOPPED: Cluster shutdown requested
2019-05-13 20:23:09,857 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: Stopping infoServer
2019-05-13 20:23:09,891 INFO  [master/master/192.168.178.37:16000] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:16010
2019-05-13 20:23:09,892 INFO  [master/master/192.168.178.37:16000] procedure2.ProcedureExecutor: Stopping the procedure executor
2019-05-13 20:23:09,892 INFO  [master/master/192.168.178.37:16000] wal.WALProcedureStore: Stopping the WAL Procedure Store
2019-05-13 20:23:09,897 WARN  [Thread-224] hdfs.DFSClient: DataStreamer Exception
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor9.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.addBlock(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:368)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.addBlock(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1449)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1270)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:526)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:09,898 ERROR [master/master/192.168.178.37:16000] wal.WALProcedureStore: Unable to close the stream
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor9.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.addBlock(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:368)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.addBlock(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1449)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1270)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:526)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:09,898 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1557765899317
2019-05-13 20:23:09,898 INFO  [master/master/192.168.178.37:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x16ab2153d450001
2019-05-13 20:23:09,901 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Session: 0x16ab2153d450001 closed
2019-05-13 20:23:09,901 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1557765899317; all regions closed.
2019-05-13 20:23:09,901 INFO  [master/master/192.168.178.37:16000-EventThread] zookeeper.ClientCnxn: EventThread shut down
2019-05-13 20:23:09,901 INFO  [master/master/192.168.178.37:16000] hbase.ChoreService: Chore service for: master,16000,1557765899317 had [[ScheduledChore: Name: LogsCleaner Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: master,16000,1557765899317-RegionNormalizerChore Period: 1800000 Unit: MILLISECONDS], [ScheduledChore: Name: CatalogJanitor-master:16000 Period: 300000 Unit: MILLISECONDS], [ScheduledChore: Name: HFileCleaner Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: master,16000,1557765899317-ClusterStatusChore Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: master,16000,1557765899317-DoMetricsChore Period: 3000 Unit: MILLISECONDS], [ScheduledChore: Name: master,16000,1557765899317-BalancerChore Period: 300000 Unit: MILLISECONDS]] on shutdown
2019-05-13 20:23:09,902 INFO  [master/master/192.168.178.37:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16201,1557765730959
2019-05-13 20:23:10,369 INFO  [master,16000,1557765899317_splitLogManager__ChoreService_1] hbase.ScheduledChore: Chore: SplitLogManager Timeout Monitor was stopped
2019-05-13 20:23:10,681 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 47 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor9.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:10,952 INFO  [master/master/192.168.178.37:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16201,1557765730959
2019-05-13 20:23:11,549 ERROR [B.defaultRpcServer.handler=5,queue=2,port=16000] master.MasterRpcServices: Region server master,16201,1557765730959 reported a fatal error:
ABORTING region server master,16201,1557765730959: Failed log close in log roller
Cause:
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor9.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1398)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.getNewPath(FSHLog.java:610)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.rollWriter(FSHLog.java:687)
	at org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:148)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 25 more

2019-05-13 20:23:11,590 ERROR [B.defaultRpcServer.handler=8,queue=2,port=16000] master.MasterRpcServices: Region server master,16201,1557765730959 reported a fatal error:
ABORTING region server master,16201,1557765730959: Unrecoverable exception while closing region hbase:namespace,,1557765908646.85da2a950d3d005ad03c657436f29eea., still finishing close
Cause:
org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=10, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1898)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:1750)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:1672)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: All datanodes 192.168.178.37:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1137)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:933)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:487)

2019-05-13 20:23:11,597 ERROR [B.defaultRpcServer.handler=24,queue=0,port=16000] master.MasterRpcServices: Region server master,16201,1557765730959 reported a fatal error:
ABORTING region server master,16201,1557765730959: Caught throwable while processing event M_RS_CLOSE_REGION
Cause:
java.lang.RuntimeException: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=10, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:152)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:129)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=10, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1898)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:1750)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:1672)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128)
	... 3 more
Caused by: java.io.IOException: All datanodes 192.168.178.37:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1137)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:933)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:487)

2019-05-13 20:23:11,683 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 48 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor9.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:12,000 INFO  [master/master/192.168.178.37:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16201,1557765730959
2019-05-13 20:23:12,686 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 49 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor9.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:13,051 INFO  [master/master/192.168.178.37:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16201,1557765730959
2019-05-13 20:23:13,689 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 50 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor9.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:14,075 INFO  [master/master/192.168.178.37:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16201,1557765730959
2019-05-13 20:23:14,690 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 51 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor9.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:15,099 INFO  [master/master/192.168.178.37:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16201,1557765730959
2019-05-13 20:23:15,694 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 52 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor9.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:16,124 INFO  [master/master/192.168.178.37:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16201,1557765730959
2019-05-13 20:23:16,697 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 53 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor9.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:17,146 INFO  [master/master/192.168.178.37:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16201,1557765730959
2019-05-13 20:23:17,701 WARN  [LeaseRenewer:root@master:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-83612137_1] for 54 seconds.  Will retry shortly ...
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor9.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2019-05-13 20:23:17,848 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [master,16201,1557765730959]
2019-05-13 20:23:17,848 INFO  [main-EventThread] master.ServerManager: Cluster shutdown set; master,16201,1557765730959 expired; onlineServers=0
2019-05-13 20:23:17,851 INFO  [master/master/192.168.178.37:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x16ab2153d450002
2019-05-13 20:23:17,854 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Session: 0x16ab2153d450002 closed
2019-05-13 20:23:17,855 INFO  [master/master/192.168.178.37:16000] hbase.ChoreService: Chore service for: master,16000,1557765899317_splitLogManager_ had [] on shutdown
2019-05-13 20:23:17,855 INFO  [master/master/192.168.178.37:16000] flush.MasterFlushTableProcedureManager: stop: server shutting down.
2019-05-13 20:23:17,855 INFO  [master/master/192.168.178.37:16000] ipc.RpcServer: Stopping server on 16000
2019-05-13 20:23:17,855 INFO  [master:16000.activeMasterManager-EventThread] zookeeper.ClientCnxn: EventThread shut down
2019-05-13 20:23:17,855 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: stopping
2019-05-13 20:23:17,856 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2019-05-13 20:23:17,856 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2019-05-13 20:23:17,869 INFO  [master/master/192.168.178.37:16000] zookeeper.ZooKeeper: Session: 0x16ab2153d450000 closed
2019-05-13 20:23:17,869 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: stopping server master,16000,1557765899317; zookeeper connection closed.
2019-05-13 20:23:17,869 INFO  [master/master/192.168.178.37:16000] regionserver.HRegionServer: master/master/192.168.178.37:16000 exiting
2019-05-13 20:23:17,869 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
2019-05-13 20:23:17,878 ERROR [Thread-5] hdfs.DFSClient: Failed to close inode 41838
java.net.ConnectException: Call From master/192.168.178.37 to master:9000 failed on connection exception: java.net.ConnectException: Verbindungsaufbau abgelehnt; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor9.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.addBlock(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:368)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.addBlock(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy17.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1449)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1270)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:526)
Caused by: java.net.ConnectException: Verbindungsaufbau abgelehnt
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
Mo 13. Mai 20:33:13 CEST 2019 Stopping hbase (via master)
